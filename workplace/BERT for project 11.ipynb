{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b5be6d67",
   "metadata": {},
   "source": [
    "# Подключение библиотеки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "fd78d20f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The jupyternotify extension is already loaded. To reload it, use:\n",
      "  %reload_ext jupyternotify\n"
     ]
    }
   ],
   "source": [
    "# Уведомление о завершение работы определенного ячейка (очень пригодится для машинного обучения)\n",
    "import jupyternotify\n",
    "%load_ext jupyternotify"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "2818fbe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Подключаем все необходимые библиотеки\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "# Для визуализации временных рядов\n",
    "import plotly.graph_objects\n",
    "import seaborn as sb\n",
    "from scipy import stats as st\n",
    "# Время обучения модели\n",
    "import timeit\n",
    "# Тренды и сезонность\n",
    "from statsmodels.tsa.seasonal import seasonal_decompose\n",
    "# Проверка на стационарность\n",
    "from statsmodels.tsa.stattools import adfuller, kpss\n",
    "# Проверка на дисперсию с помощью теста Андерсона-Дарлинга\n",
    "from scipy.stats import anderson\n",
    "# XGBRegressor\n",
    "import xgboost as xgb\n",
    "\n",
    "# Работа с текстами\n",
    "import nltk\n",
    "from nltk.corpus import stopwords as nltk_stopwords\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "from lightgbm import LGBMRegressor\n",
    "# Вызов библиотеки для отключения предупреждения\n",
    "import warnings\n",
    "\n",
    "# Разбиение на обучающую, валидационную и тестовую выборку\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score, cross_val_predict, TimeSeriesSplit\n",
    "# Применим кроссвалидацию для повышения качеств обучения\n",
    "\n",
    "\n",
    "\n",
    "# Масштабируемость модели\n",
    "from sklearn.preprocessing import StandardScaler, OrdinalEncoder, OneHotEncoder\n",
    "\n",
    "# Для машинного обучения разными способами:\n",
    "# - Логическая регрессия\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "# - Случайный лес\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "# - Решающее дерево\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "# - Модель на адекватность\n",
    "from sklearn.dummy import DummyClassifier\n",
    "# - Бустинг модель\n",
    "from catboost import CatBoostClassifier\n",
    "\n",
    "from sklearn.metrics import (\n",
    "    # Точность модели\n",
    "    accuracy_score,\n",
    "    # Матрицы ошибок (для борьбы с дисбалансом)\n",
    "    confusion_matrix, \n",
    "    # Полнота\n",
    "    recall_score, \n",
    "    # Точность\n",
    "    precision_score, \n",
    "    # F1-мера\n",
    "    f1_score,\n",
    "    # Метрика AUC-ROC\n",
    "    roc_auc_score,\n",
    "    roc_curve,\n",
    "    # MSE\n",
    "    mean_squared_error,\n",
    "    mean_absolute_error,\n",
    "    fbeta_score, \n",
    "    make_scorer\n",
    ")\n",
    "\n",
    "# Контроль выборки\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "# Для лематизации текстов\n",
    "import re\n",
    "from pymystem3 import Mystem\n",
    "\n",
    "# Для машинного обучения - деление выборки на обучающие и валидационные\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "# Просмотр все значений метрики\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "from sklearn import svm\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db620d24",
   "metadata": {},
   "source": [
    "Для машинного обучения с BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "1ef77259",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import torch\n",
    "\n",
    "# Библиотеки для обучения с применением технологий BERT\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "# import tensorflow_text as text\n",
    "from transformers import BertTokenizer\n",
    "# Чтобы создать AdamW оптимизацию\n",
    "from official.nlp import optimization  \n",
    "\n",
    "tf.get_logger().setLevel('ERROR')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "f6b51b0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Получаем датасет\n",
    "try:\n",
    "    # С локального файла\n",
    "    try:\n",
    "        # Сразу устанавливаем время как индексы\n",
    "        df = pd.read_csv('toxic_comments.csv', index_col=[0], parse_dates=[0])\n",
    "    except:\n",
    "        df = pd.read_csv('/datasets/toxic_comments.csv', index_col=[0], parse_dates=[0])\n",
    "except:\n",
    "    print('Отсутствует датасет. Проверьте путь файла')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81c1a565",
   "metadata": {},
   "source": [
    "# Предобработка данных"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53877696",
   "metadata": {},
   "source": [
    "## Разделим на обучающую и тестовую выборку"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "359f9d5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Деление обучающей выборки на признаки и целевые признаки\n",
    "features = df['text']\n",
    "target = df['toxic']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2738eb04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Разделим обучающую и тестовую выборку\n",
    "features_train, features_test, target_train, target_test = train_test_split(features, target, test_size=0.25, random_state=12345)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "dcdfbf32",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Размер обучающей выборки: 0.75 %\n",
      "Размер тестовой выборки: 0.25 %\n"
     ]
    }
   ],
   "source": [
    "print('Размер обучающей выборки:', round(features_train.shape[0] / df.shape[0], 3), '%')\n",
    "print('Размер тестовой выборки:', round(features_test.shape[0] / df.shape[0], 3), '%')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cba436f",
   "metadata": {},
   "source": [
    "## Корпусы текстов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2a76719b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Создаем корпус текстов\n",
    "corpus_train = list(features_train)\n",
    "corpus_test = list(features_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e6d65a4",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-danger\">\n",
    "<b>Ошибка:</b> Приводить тексты к юникоду не имеет смысла, так как они все на английском. Это может привести к падению ядра из-за увеличения объема занимаемой памяти.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5489c171",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "<b>Комментарий студента V2:</b> Хорошо, подправил\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "aea25f88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Corpus_train\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"That makes no sense. You don't play MapleStory through Internet Explorer. Sure, the website can only be accessible through IE (well, you can access it through Firefox as well if you know what to do), but it's not really part of the game.\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Corpus_test\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Expert Categorizers  \\n\\nWhy is there no mention of the fact that Nazis were particularly great categorizers? They excelled in identifying various things and writing about them and putting them in their proper places.'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print('Corpus_train')\n",
    "display(corpus_train[0])\n",
    "print()\n",
    "print('Corpus_test')\n",
    "display(corpus_test[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdf12476",
   "metadata": {},
   "source": [
    "## Установка стоп-слово"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4961262b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Papin\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# Получим стоп-слово\n",
    "nltk.download('stopwords')\n",
    "stopwords = set(nltk_stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14af8f48",
   "metadata": {},
   "source": [
    "## Создание корпуса текстов с обучающей и тестовой выборки"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "898ae3ba",
   "metadata": {},
   "source": [
    "### Обучающая выборка"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "dd84d16c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# По аналогии с CountVectorizer() создадим счётчик, указав в нём стоп-слова:\n",
    "count_tf_idf_train = TfidfVectorizer(stop_words=list(stopwords))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "eca68c75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Чтобы посчитать TF-IDF для корпуса текстов, вызовем функцию fit_transform():\n",
    "tf_idf_train = count_tf_idf_train.fit_transform(corpus_train) \n",
    "# Передав TfidfVectorizer() аргумент ngram_range, можно рассчитать N-граммы."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c1a69c9b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Размер матрицы обучающей выборки: (119469, 158310)\n"
     ]
    }
   ],
   "source": [
    "print(\"Размер матрицы обучающей выборки:\", tf_idf_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89722561",
   "metadata": {},
   "source": [
    "### Тестовая выборка"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4aa19c55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# По аналогии с CountVectorizer() создадим счётчик, указав в нём стоп-слова:\n",
    "count_tf_idf_test = TfidfVectorizer(stop_words=list(stopwords))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f9560720",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Чтобы посчитать TF-IDF для корпуса текстов, вызовем функцию fit_transform():\n",
    "tf_idf_test = count_tf_idf_train.transform(corpus_test) \n",
    "# Передав TfidfVectorizer() аргумент ngram_range, можно рассчитать N-граммы."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b9a50d71",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Размер матрицы тестовой выборки: (39823, 158310)\n"
     ]
    }
   ],
   "source": [
    "print(\"Размер матрицы тестовой выборки:\", tf_idf_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2963fd7b",
   "metadata": {},
   "source": [
    "# Машинное обучение с BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "0247352d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "d066e317",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "a7597cbd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "119469"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_idf_train.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "38025931",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 0 ns\n",
      "Wall time: 0 ns\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from tqdm import notebook\n",
    "batch_size = 2 # для примера возьмем такой батч, где будет всего две строки датасета\n",
    "embeddings = [] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c47cbda6",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:1\") if torch.cuda.is_available() else torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "43618371",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "428d6231",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8b35263edd2448db964439766980a6d3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/59734 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "TypeError",
     "evalue": "sparse matrix length is ambiguous; use getnnz() or shape[0]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "File \u001b[1;32m<timed exec>:2\u001b[0m\n",
      "File \u001b[1;32mD:\\Program File\\Anaconda\\lib\\site-packages\\scipy\\sparse\\_base.py:345\u001b[0m, in \u001b[0;36mspmatrix.__len__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    344\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__len__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m--> 345\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msparse matrix length is ambiguous; use getnnz()\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    346\u001b[0m                     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m or shape[0]\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mTypeError\u001b[0m: sparse matrix length is ambiguous; use getnnz() or shape[0]"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for i in notebook.tqdm(range(tf_idf_train.shape[0] // batch_size)):\n",
    "        batch = torch.LongTensor(tf_idf_train[batch_size*i:batch_size*(i+1)]).cuda() # закидываем тензор на GPU\n",
    "        attention_mask_batch = torch.LongTensor(attention_mask[batch_size*i:batch_size*(i+1)]).cuda()\n",
    "\n",
    "        with torch.no_grad():\n",
    "            model.cuda()\n",
    "            batch_embeddings = model(batch, attention_mask=attention_mask_batch)\n",
    "\n",
    "        embeddings.append(batch_embeddings[0][:,0,:].cpu().numpy()) # перевод обратно на проц, чтобы в нумпай кинуть\n",
    "        del batch\n",
    "        del attention_mask_batch\n",
    "        del batch_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aabbceb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = np.concatenate(embeddings) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3b4b104",
   "metadata": {},
   "source": [
    "## Получение датасета"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f40592b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Получаем csv файл через ссылки\n",
    "toxic_comments_path = tf.keras.utils.get_file(\"toxic_comments.csv\", 'https://code.s3.yandex.net/datasets/toxic_comments.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "142ed19c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\Papin\\\\.keras\\\\datasets\\\\toxic_comments.csv'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Адрес хранения csv файла\n",
    "toxic_comments_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f95a794e",
   "metadata": {},
   "outputs": [],
   "source": [
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "batch_size = 32\n",
    "\n",
    "toxic_comments_csv_ds = tf.data.experimental.make_csv_dataset(\n",
    "    'toxic_comments.csv',\n",
    "    label_name='',\n",
    "    batch_size=batch_size,\n",
    "    num_epochs=1,\n",
    "    ignore_errors=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb8181b8",
   "metadata": {},
   "source": [
    "Просмотр текстов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "e5e2ee01",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text                : [b'\"|decline=You felt it necessary to repeatedly make this edit, which is considered vandalism. \\xe2\\x80\\x94 \\\\\\xc2\\xa0talk\\xc2\\xa0/ }}\"'\n",
      " b\"Current Events Story\\nHi, I removed the story you posted on Cuurent Events for several reasons:\\n The story didn't seem to belong on the date where you placed it. If the story was reported in a newspaper dated January 13th, it shouldn't be listed under the January 20th events.\\n I know this may be an important story in Belize, but (as far as I can tell) only one newspaper is carrying it and there are no hits on Google News. It doesn't appear to be of global importance, which is usually what it takes to be included on Current Events.\\n The summary was way too long. Two or three sentences is usually the maximum for a summary. If it wasn't for the first two points, I would have attempted to edit the summary instead of deleting. \\n\\nFor now, I'm going to remove the story, but if you can find more sources, please feel free to include a short summary and link on the correct date.  18:44, 20 Jan 2005 (UTC)\"\n",
      " b\"C.D. Strand - Ranking The President (2003) \\n\\nI found this ranking, but I am having some difficulty adding it with the coding place.  Could someone add it?  Here's the link to poll  http://www.cdstrand.com/areas/essays/presranks.htm\"\n",
      " b'propfan MD-80 \\n\\nI read that during a period of unusually high fuel costs, MD built one -80 with propfan engines (these look like turbofans, but with a propellor attached to the rear; they are known for their effeicency). After some initial hype, no orders came, and the model (I believe it was a one-off, more of a demonstrator than anything else), was scrapped. There has been intermitent talk of using propfans on civil aircraft since then, but it has not come to anyhting.'\n",
      " b'That works too. ;)'\n",
      " b'\"\\n\\n, I must object quite strongly to your removal of the bolded text from this sentence: \\n\"\"Furthermore, intelligent design is neither observable nor repeatable, which critics argue violates the scientific requirement of falsifiability.\"\"\\n\\nThis is an accurate statement in it\\'s entirety and does not contain any weasal words. I don\\'t understand your purpose in removing the text, but I\\'m willing to hear your explanation.\\n\\nI must also object to your edit summary which accused me of trying to trick you, and of reverting all your edits. To the best of my knowledge, we have never interacted before and I have never reverted any of your edits before. To claim that I am somehow trying to trick you is nothing short of ludicrous. I suggest that an apology is in order, in addition to some explanation.  Tropics \"'\n",
      " b'Hi a, Bhadaniji is a magniloquocent personage. He will remember your service and mention you thankfully in his magnimum oppositus to be published soon.'\n",
      " b'myself. You may leave a message at the talk page f the article if you disagree with my evaluation'\n",
      " b'\"\\n\\nFantastic!!! Thank you!!  That\\'s extremely helpful.  That biography contains details of his early and late life that do not exist in the other sources (I\\'ve got his time in Paris pretty well fleshed out  Slonimsky\\'s reminiscences in Perfect Pitch are full of juicy details).  I\\'m still trying to understand all the Orthodox religious references in some of my other sources; e.g. two resurrections?  I\\'m a little out to sea on some of that.  It\\'s hard to write about his 12-tone method without doing forbidden \"\"original research\"\" because it seems no one has really studied it in depth  Sitsky maybe more than anyone else  I really want to look at one of the scores.  Now if only I had a public domain illustration or two ...  Anyhow now I can cite that biography, thanks to you!  I\\'m presuming that the \"\"World Encyclopedia\"\" in Russian is a reliable source.  (Everything sounds right, and matches up with Grove and the others I\\'ve got.)  Cheers,  (talk) \"'\n",
      " b'IDIOT \\n\\nYOU JUST GO AROUND UNVALDALIZING WIKIPEDIA, YOU retard. WHO THE HELL LIKES WIKIPEDIA ANYWAY. YOU EVEN REQUESTED MY PAGE BE DELETED. KEEP YOUR HANDS OUTTA MY BUISNESS'\n",
      " b'\"\\nYes they are indeed.  I\\'ve replaced that second one with a summary of Women\\'s rights  talk \"'\n",
      " b'Welcome. I stumbled on it when I started to work on the endangered sites.'\n",
      " b'Yes, I felt that seeing as most people know Elizabeth Woodville was the ancestor of all the English monarchs after 1509, it was redundant to mention it, but as you rightly pointed out, it appeared to be an oversight, so thank you for drawing my attention to it.'\n",
      " b\"It's not possible it was!!! All this bickering because two individuals want to sweep away 8 yrs of helping and research because they they enjoy the power WP gives them through its rules! THERE OUTTA BE A RULE AGAINST RULES!!! Your humble servant! Subwayjack\"\n",
      " b'Tbma\\n\\nI think its very unfair to compare my edits with those of Tbma/YMB29, first i have been the main contributor to this article, i have seeked the sources/ disscused in discusion all in line to improve this article, this is not the case with Tbma/YMB29 who just last week consider the whole article a hoax, also today i really displined myself not doing any of the previuslly acts of misconduct, so i think your crttisism of me is utterlly unfair.Posse72 (talk) 22:13, 24 July 2010 (UTC'\n",
      " b\"I don't care what you say here. I don't believe one sentence anymore.\"\n",
      " b'Also, what does a deceased radio host have to do with what age you think I am? My nickname is based on my given name, not the radio host or the Star Wars character.'\n",
      " b'\"\\n\\n =^_^= \\n\\nI just watched the entire series, and I agree, this entire article and several other in the suzumiya haruhi articles are all from a \"\"somebody who knows haruhi personally\"\" sort of view.\\n\\nSo Im going to fix it.\\n\\n \"'\n",
      " b'\"\\n\\nDid you scout for sources prior to the prod? Eh, no.... \\xe2\\x99\\xa6 Dr. Blofeld \\n\\n\"'\n",
      " b\"For further info.... \\n\\nEllo there, the Doctor here... Here's a link concerning the * if you hadn't already checked out the TCW talk page. It's from a pretty good episode too, although the image on the episode article here is from In a Mirror, Darkly... That rather bugged me. Anyways, thanks for pointing out a possible inconsistency in the dimensional drift of the article. These things always need improving...\\nMany happy returns.\"\n",
      " b'http://www.imdb.com/name/nm2551199/filmoseries#tt1327666 71.223.125.139'\n",
      " b'Im sorry are you fucking stupid that nice person just gave me a warning then you fucking block me, nigger cunt eat pussy bitch'\n",
      " b\"APEC Anarchy Week==\\nCan't wait to join in with the protest. Need to get my soap for the free bath.\\n\\n==\"\n",
      " b'\"\\nAgreed, but how would you describe it ? It is not a design, but what is it ? \\nWhen you find the answer to that question, you\\'ll find a great way to label the image.   \\xe2\\x98\\x8f 11:23, 25 Jun 2012 (UTC)\"'\n",
      " b'\"\\n\\nCheck this one out;)   23:57, September 7, 2005 (UTC)\"'\n",
      " b'\"::Hey I posted my fave B&B; characters on MF\\'s talk page, sorry just don\\'t feel like copying them down again lol. Thank you MF my god I always hated Bill and Katie together. I\\'m starting to hate Heather Tom but I still love Katie P I love Don Diamont too just hated him on Y&R.; Highly doubt he got better from when I watched in the 80s. Maura was Diane Jenkins? Really? I remember her from Y&R; back in the early 80s. She was some slut who was portrayed by some Donnelley girl. I totally can\\'t picture Maura as Diane. Eeew! Anyway if you\\'re fearing the future for GH then I won\\'t start watching again. I wanted to get back into it this year but if it\\'s still crummy storylines then screw it lol. BTW is Leslie Charleston still on GH?? Didn\\'t she portray like someone named Monica or something?? Yeah I hate The Talk. It was such a poor replacement for ATWT, if they wanted to cancel it then the actors can just come to my house and perform the soap for me on the spot!!! lol. I hate Sharon Osbourne and that random girl from Roseanne. Anyway, get back to me!! I love chatting with you it brightens up my day )  Talk? \\n\\n\"'\n",
      " b'\" March 2012 (UTC)\\n\"\"That sentence assumed that there was wrongdoing. The rest of that section still implies it by the juxtaposition of the funding information with the report details. You may think that this is obvious, but we need a source that explicitly states that the findings of the the UT report were influenced by the funding received.\"\"Perhaps personal correspondence with the authors of the Texas study admitting their findings were indeed swayed by the knowledge that the business interests of major donors to their institution and research programmes would likely be substantially affected in the negative if said findings did not produce a clean bill of health for fracking? I mean, that\\'s about the only way you could ever meet your demand. What an utterly absurd request. It\\'s easy to see why it was made, though: just set the bar so high it can\\'t be jumped, then use the failure as an excuse to chop out what you don\\'t like. Maybe you\\'d have me hack the e-mail accounts of the authors, fish around for evidence (assuming there is even any there), then leak it to a major newspaper so they can write an article that I can cite on here. Only the most naive idiot can fail see the potential for conflict of interest from a study put out by Texas. The university\\'s state is the heart and soul of US oil & gas, but that\\'s certainly not worthy of so much as a mention given that which is also true: the university has multi-million-dollar and other links with the largest provider of fracking services in the United States, not to mention other oil & gas companies with interests in fracking. I have no idea whether their report was swayed by industry links, but only a fool would suggest the potential isn\\'t there. If you don\\'t like the juxtaposition, just open up a gap with a caveat\\xe2\\x80\\x94and make it as weak, pathetic and denigrating as you like for all I care, maybe something like, \"\"socialist\\xe2\\x80\\x94nay, communist!\\xe2\\x80\\x94campaigners in the pay of a European Maoist group have alleged a potential for a conflict of interest, noting that...\"\" For comparison, take the recent global-warming sceptics at the Heartland Institute: as soon as details of the Institute\\'s funding were leaked, they were prominently reported in the press. We don\\'t even need leaks here, the information is freely available to anyone who takes the time to find it out, as Smm201`0 and others have done. All you are interested in doing is eliminating even mention of perfectly obvious potential for conflict of interest. According to Ian Urbina, we can\\'t even get a decent, untarnished report out of the EPA; unlike Texas, the EPA doesn\\'t even take industry funding, for god\\'s sake, yet still it can\\'t escape heavy industry pressure to redact. Aside from irrelevances like minor earthquakes, I have no idea whether fracking is causing all the problems it is alleged to, though I am extremely suspicious given the documented efforts of industry (and their paid-for puppets in government) to tone down or eliminate negative findings, and the truly just ridiculous claims about fracking\\'s potential by people like Lord Browne here in England. And I couldn\\'t care less if fracking\\'s safe or not. Why should I? or anyone? If it\\'s not, it\\'s not; if it is... it is! Outside of a lunatic asylum, who would care? If it is safe (enough), bring it on: jobs, tax receipts, increased energy security, reduced use of coal burning... only a fool wouldn\\'t be interested in those things, particularly given the current economic situation. What I don\\'t like are those desperate only to hear what they want to hear making up totally unreasonable tests so they can get rid of what they regard as offending material.~   00:59, 28\"'\n",
      " b\"You are reaching someone but I can't make out what you are trying to say and you aren't signed in so I don't know who you are.\"\n",
      " b'Vandalism\\n\\nMONGO removed all of the Tags I placed about problems with the article.\\nhttp://en.wikipedia.org/w/index.php?title=Chad_Kellogg&diff;=603899892&oldid;=603899206\\nThe Tags specify that they should remain until the problems are resolved.  Potential Vandalism again.\\nhttp://en.wikipedia.org/w/index.php?title=Chad_Kellogg&diff;=603899892&oldid;=603899206'\n",
      " b\"Hi Explicit, can you block O Fenian for edit-warring on the Giant's Causeway wp. He has made several edits which can only be described as terrorism.\"\n",
      " b'\"\\n\\nAre you a pole smoker? Do you suck cock?  \\xe2\\x80\\x94Preceding unsigned comment added by 173.70.228.251   \"'\n",
      " b\"It's the sources that matter to me. Now, do have GNU/Linux naming controversy that discusses this and, yes, consensus is important. However, for this package, I would side with the GNU/Linux side, but not all.\"]\n",
      "-------------------------------------------------------------------------------------------------------------------------------\n",
      "toxic               : [0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0]\n",
      "-------------------------------------------------------------------------------------------------------------------------------\n",
      "===============================================================================================================================\n",
      "\n",
      "label               : [3731 1278 2459 6514 5992 8239 1214 9924 2614 7030  251 7129 9483 1859\n",
      " 2369  503 6198  515  664 2742 6186 2434 7057 1494 4027 8644 7767 7235\n",
      " 2329   38 8965 6500]\n"
     ]
    }
   ],
   "source": [
    "for batch, label in toxic_comments_csv_ds.take(1):\n",
    "    for key, value in batch.items():\n",
    "        print(f\"{key:20s}: {value}\")\n",
    "        print('-'*127)\n",
    "    print('='*127)\n",
    "    print('')\n",
    "    print(f\"{'label':20s}: {label}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "666a314f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<PrefetchDataset element_spec=(OrderedDict([('text', TensorSpec(shape=(None,), dtype=tf.string, name=None)), ('toxic', TensorSpec(shape=(None,), dtype=tf.int32, name=None))]), TensorSpec(shape=(None,), dtype=tf.int32, name=None))>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "toxic_comments_csv_ds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cd8400b",
   "metadata": {},
   "source": [
    "##  Деление на обучающей и тестовой выборки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "14cac6c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Разделим обучающую и валидцаионную, тестовую выборку в соотношение 60:40\n",
    "train, test = train_test_split(df, test_size=0.2, random_state=12345)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "c21d44ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Размер обучающей выборки: 0.8 %\n",
      "Размер тестовой выборки: 0.2 %\n"
     ]
    }
   ],
   "source": [
    "print('Размер обучающей выборки:', round(train.shape[0] / df.shape[0], 3), '%')\n",
    "print('Размер тестовой выборки:', round(test.shape[0] / df.shape[0], 3), '%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "b4eb3c62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cохраняим файлы\n",
    "train.to_csv(r\"toxic_comments_train.csv\")\n",
    "test.to_csv(r\"toxic_comments_test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "f003840b",
   "metadata": {},
   "outputs": [],
   "source": [
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "batch_size = 32\n",
    "\n",
    "toxic_comments_csv_ds_train = tf.data.experimental.make_csv_dataset(\n",
    "    'toxic_comments_train.csv',\n",
    "    label_name='',\n",
    "    batch_size=batch_size,\n",
    "    num_epochs=1,\n",
    "    ignore_errors=True)\n",
    "\n",
    "toxic_comments_csv_ds_test = tf.data.experimental.make_csv_dataset(\n",
    "    'toxic_comments_test.csv',\n",
    "    label_name='',\n",
    "    batch_size=batch_size,\n",
    "    num_epochs=1,\n",
    "    ignore_errors=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a624394",
   "metadata": {},
   "source": [
    "Просмотр текстов обучающей выборки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "7a0bac8f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text                : [b\"Mooriddengirl: I'd appreciate it if you would unblock me or leave a note to allow another administrator to unblock me.  I've followed all the Wikipedia suggestions and I have apologized, I've stated I won't do it again, and I'd like you and the others to show good faith towards me.  Thanks\"\n",
      " b\"Rookie Award \\n\\nOn 14 July, it was announced that EXO has won 2012 Best Rookie Award of Japan's Tower Records 'K-Pop Lovers! Award'. Tower Records is the largest music store in Japan.\\n\\nJapan's Tower Records reported the results which combines internet users' vote and album sales in Japan from January of this year till June. Their debut album MAMA recorded over 100,000 copies sales in just two months. The grand total of the album placed the group to become the biggest selling rookie in 2012 so far.\"\n",
      " b\"Bushranger you're a GRASS with no sense of humour. Seen the South Park episode Poor and Stupid? That's what I was referring to, a comment obviously lost on you. But you've shown you can't fight your own battles and have to run crying to mummy - boo-hoo.90.204.13.4\"\n",
      " b'\"\\n\\nWell I feel like Im getting ganged up on here, all I wanted to do was add two sentences to an article and I\\'m forced into arguing with someone over whether or not it should be in the article. If I argue with him then I am \"\"engaging in personal attacks.\"\" If I dont argue with him then I am not listening to the consensus opinion, which seems to be only him. So basically I am in a lose lose situation and now am banned for no reason. (  )\"'\n",
      " b'Thanks for putting up the CU. I will add to it as soon as I am free. Unlike the last time where the admin closed it for lack of disruptive editing, this time we have reason to beleieve that Raunak was merely preparing socks for a longdrawn edit war. If you have followed the Brahmosim related threads(Ill post you the links soon), you might know what I am talking about. \\nB.t.w if I a remeber correctly his first account was  (talk \\xe2\\x80\\xa2 contribs)'\n",
      " b'Maybe, rather than spending the time writing the above, could you mot have spent the time just editing and rewording the offending content in order to remove the copyright issue?'\n",
      " b\"Look at your own fucking speech before you criticise others you stupid idiot, you are a bully, you think you own the Megadeth discography page and revert anything you don't agree with. I gave in to you regarding the formats and label numbers but I won't over this.\"\n",
      " b'\"\\n\\n Please do not vandalize pages, as you did with this edit to Erick Morillo. If you continue to do so, you will be blocked from editing \\xe2\\x80\\x93 Gurch \"'\n",
      " b'REDIRECT Talk:Williamson County Regional Planning Commission v. Hamilton Bank of Johnson City'\n",
      " b'You made a mistake \\nYou reverted an edit I made requesting a citation, and marked it as vandalism.  The request for citation is appropriate by Wiki guidelines.  Your assumption that said edit was vandalism also did not assume good faith, and I honestly have no idea how you could have come to the conclusion that it was vandalism.'\n",
      " b\"I think KC's version is a good start but I generally agree with Mastcell's comments - MC can you propose your revision or version (I mean, make the changes you advocate and show us what the result is for the whole passage)?    |  Talk\"\n",
      " b'OK Kitty I had a look at that. Now where can I see Terms of Reference, Procedures, Timetables etc for WP:IECOLL?'\n",
      " b'\"\\n\\nThis is not funny, guys. Look at their respective article\\'s pictures. It looks like someone took the Pratchett pic, rotated it, and changed the subject\\'s outfit. Personally, I\\'m surprised that Dan Brown (the name that I\\'m currently using for Randi/Pratchett until I figure out what his real name is) didn\\'t bother to dye his hair. \\n\\nAdding to the suspiciousness is the fact that both of them have had heart complications. Very CONVENIENT heart complications, which allows \"\"Pratchett\"\" and \"\"Randi\"\" to make public appearances in two different locations. \\n\\nIf anyone can find me PROOF in the form of a real, unedited photograph that picture BOTH Randi and Pratchett IN THE SAME PLACE at the SAME TIME, then I will personally give you a million dollars as well as a million copies of the newest Pratchett novel  Thud.  \"'\n",
      " b\"Get a life \\n\\nLook saddo, I don't know who you are, but you know... get a life. To be honest, does it matter that much that I don't know a website where what was said was said, and let me assure you, The Times newspaper is a fairly reliable source in my book. \\n\\nDo you have a job? Because the kind of person who checks every page for edits, and their reliability is a pretty sad little man (or woman, I don't know what yamla is)\\n\\nBefore you say anything, or 'cite me for blocking' or some crap, this profile was only made because the school ip was blocked, and I edited a page about the Crusades. Happy?\"\n",
      " b'\"::You know, none of us are at your beck and call. Sometimes we have to attend to other matters in our life, so we can\\'t provide instantaneous reponses to you. My apologies if this offends. By the way, the answers are above. I should also point out that you won\\'t get anywhere in Wikipedia if you continue to issue commands as you have in this talk page. matrix \\n\\n\"'\n",
      " b\"Because there's a minor character in there by that name. He is confused with Youssarian by the Psychiatrist, resulting in Fortiori going home because Youssarian acts crazy.\"\n",
      " b'\"\\nThe problem with that argument is that it assumes your presence will help to build an encyclopedia, and there are quite a few people who feel your past behavior has hindered the building of it, wasted their time, or will be a distraction to them and others on here if you are back.  Just because it\\'s the encyclopedia that anyone can edit, doesn\\'t mean it is the encyclopedia that everyone should edit.  That idea seems to be lost on some critics, that there is no \"\"right to edit Wikipedia\"\".  David \\'\\'\\'\\'\\'\\' \\n\"'\n",
      " b', and welcome to Wikipedia! Thank you for your contributions. I hope you like the place and decide to stay. Here are a few good links for newcomers:\\nThe five pillars of Wikipedia\\nHow to edit a page\\nHelp pages\\nTutorial\\nHow to write a great article\\nManual of Style\\nI hope you enjoy editing here and being a Wikipedian! Please sign your name on talk pages using four tildes (~~~~); this will automatically produce your name and the date. If you need help, check out Wikipedia:Where to ask a question, ask me on my talk page, or place {{helpme}} on your talk page and someone will show up shortly to answer your questions. Again, welcome!'\n",
      " b'Revised version is much better.  Thanks. -  18:28, 9 Jun 2004 (UTC)'\n",
      " b\"SummerPhd, MarnetteD and several other editors suck enormous amounts of cock.  They're faggot queer douchebags who go on a power trip because they're wikipedia editors...even though that means that they're doing nothing with their lives and still live in their mom's basements.  What fucking losers. HAHAHA I already have another account who can edit semi-protected pages...they're just fighting a losing battle.  Douchebags.\"\n",
      " b\"It seems to me that the term 'SLA' has basically come to mean a fairly narrow approach to doing research on learning an L2such as the experiments reported by Ellis. That is a shame because this sort of experimentation is so fruitless. But its an undertaking that a number of university-based academics gets paid to pursue, so it has taken on an undeserved legitimacy. It's now quite distinct from 'applied linguistics'(AL) since so little of linguistics informs the concepts and interpretations of current SLA research. 133.7.7.240\"\n",
      " b'Please Check history page at 3RR page. My reports have been vandalized by G2bambino. They do not reflect what I posted.'\n",
      " b'Third party:Those details look better suited in Criticism of Wikipedia. A passing mention in the relevant section can be considered.'\n",
      " b\"Thanks and a Suggestion \\n\\nThank you for your kind words and support.  I think you cause would be served more efficiently if you took your thought to the related discussion on the Plug-In Hybrid talk page.  Also, while I recognize that their are reasons to maintain one' anonymity, I might suggest that creating an account might help your position in cases similar to this one.  Cheers,\"\n",
      " b'Piss Off \\n\\nSuck my dick you pussy'\n",
      " b'History of indicators \\n\\nIt would be useful to have charts showing changes in key indicators like GDP, growth rate, and unemployment, over several decades.'\n",
      " b'EFFIGY STUDIOS \\n\\nSorry to report this, but according to the Michigan Business Lookup website. Eminem is NOT the owner of Effigy Studios. A Thomas W. Johnson is listed as the owner. \\n\\nSee here.'\n",
      " b'Big Brother Australia 2012 \\nI see you have partially completed the process for nominating Big Brother Australia 2012 as an Article for Deletion. However, you have not completed the process. Are you withdrawing the nomination?'\n",
      " b\"Mexico a Regional Power? \\n\\nI don't agree that Mexico is a Regional Power at least of Latin America, it could be a Regional Power of Central America, but nowadays it is considered to be part of North America.\\nIn the other areas of the world, the article is divided between East, West, North, South not between ethnic or languagegroups. If this was the case in Europe it could be considered, Latin, Germanic, Slave and even Anglo-Saxon groups.\\nIf we consider this, in the Americas case it should be South America and not Latin America.\\nSecond case, Mexico has a great GDP but in overal terms GDP is not the only factor, we should consider military, power projection and foreign policy. Mexico has a ridiculous military and projection power and politically is a subalternous nation to the USA \\nArgentina, Venezuela or Colombia have greater military and power projection capabilities, historically they have been much more interventionous and agressive toward other nations than Mexico and today we can see the same, specially in Venezuela case.\\n\\n 16:11, 13 May 2007\\nPersonally I agree with you, but you need sources to say it. This encyclopedia is not a place for Orignal Research. Furthemore, editors have produced sources saying Mexico is a Regional Power of Latin America, if we change it to South America there would be no place in wich to put Mexico. Besides, Brazil's influence is not restricted to South America, it would not make sense to say it is restricted since the sources don't agree.\"\n",
      " b'\"\\n\\nSpeedy deletion of Dustin Garringer\\n A tag has been placed on Dustin Garringer requesting that it be speedily deleted from Wikipedia. This has been done under section A7 of the criteria for speedy deletion, because the article appears to be about a person or group of people, but it does not indicate how or why the subject is notable: that is, why an article about that subject should be included in an encyclopedia. Under the criteria for speedy deletion, articles that do not assert the subject\\'s importance or significance may be deleted at any time. Please see the guidelines for what is generally accepted as notable, as well as our subject-specific notability guideline for biographies. \\n\\nIf you think that this notice was placed here in error, you may contest the deletion by adding  to the top of the article (just below the existing speedy deletion or \"\"db\"\" tag), coupled with adding a note on the article\\'s talk page explaining your position, but be aware that once tagged for speedy deletion, if the article meets the criterion it may be deleted without delay. Please do not remove the speedy deletion tag yourself, but don\\'t hesitate to add information to the article that would would render it more in conformance with Wikipedia\\'s policies and guidelines.   \"'\n",
      " b'\"\\n\\n Re:You reverted my edit!\\nThis is a pretty trivial matter, but anyway... I reverted your \"\"delightful\"\" edit because the image you added looked tacky. It is hardly the custom for subject userboxes to contain pictures. and it looks terrible. Rest assured, however, that we\\'re all just as amazed that you can use LaTeX. WOW!  \"'\n",
      " b\"He makes it kinda obvious, doesn't he? '''' talk\"]\n",
      "-------------------------------------------------------------------------------------------------------------------------------\n",
      "toxic               : [0 0 1 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0]\n",
      "-------------------------------------------------------------------------------------------------------------------------------\n",
      "===============================================================================================================================\n",
      "\n",
      "label               : [ 82075  51063  97494  57647  49477  57763  87695  65196  39444 150302\n",
      "  64181 145979 135170 118196 115664  27734 136751  94404   2759  48843\n",
      "  36434 155713 123638  46589  51802   4387 158330  43029   5978  65459\n",
      "  83362 130422]\n"
     ]
    }
   ],
   "source": [
    "for batch, label in toxic_comments_csv_ds_train.take(1):\n",
    "    for key, value in batch.items():\n",
    "        print(f\"{key:20s}: {value}\")\n",
    "        print('-'*127)\n",
    "    print('='*127)\n",
    "    print('')\n",
    "    print(f\"{'label':20s}: {label}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7e34d2e",
   "metadata": {},
   "source": [
    "Просмотр текстов тестовой выборки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "8e0744b8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text                : [b\"Re:Bonjour! \\nHow did you know I'm taking French classes? That really helps, please keep going. I'm not editing articles too much, school and this are taking up my time. I'm glad to see you've returned, Fred. I missed you.\"\n",
      " b\"Do you actually believe in such a fairy tale?  The guy has been living in the US for half of his life and he doesn't have a US citizenship?  Cmon, use your common sense.  Do you actually believe he's been applying for his green card over and over?  It would be much easier if he had owned any companies in the US and didn't he own half of the Coyotes?\"\n",
      " b\", 12 April 2007 (UTC)\\nTabloids can be accurate sources - sometimes. Occasionally. Rarely, even. Show us a link! Our local paper usually picks up on absurd British stories, but I haven't heard of this one over here in AU.  02:00\"\n",
      " b'WHY U ALL DELETIN MY PAGES DOG?'\n",
      " b'\"\\n\\n This is an interesting discussion with good points made by all. I can add a little bit that might be helpful. As mentioned by the editors above the dictionay definition and a legal definition are not the same and one state\\'s legal definition might be different from another\\'s. So why not say this in the article. What definition a reader needs or wants depends on their purpose. For example, if a young person is reading a book meant for older persons and comes across the word adultery, his needs will be far different than those of a lawyer who\\'s client walks in and says, \"\"They charged me with \\'adultery\\'; what\\'s that?\"\" In the first case the reader might need nothing more than a dictionary definition (or perhaps a little more, particularly that it is rare for someone to go to jail for it), and in the second case, the lawyer will want to explain all the elements of the crime (each thing that must be proved by the government in order to find someone guilty, including that it was done knowingly, etc.).\\n\\n The beginning could say: \"\"Adultery, in some jurisdictions a crime or a tort (a civil wrong) is generally defined as (insert dictionary definition). However in the legal context of a person actually being charged with adultery as a crime or cited as a grounds for a divorce or other lawsuit, a more precise definition would be required.\\n\\n The term adultery usually refers to the rarely prosecuted common law or statutory crime relating to having extra-marital relations, but usually in an informal or literary context not in a legal context.\\n\\n In ordinary usage the vagueness of the term is not a hindrance to communication, as the scope of the term is understood to change from context to context, some requiring more specifics than others. In a legal sense, residents of the United States, for example, understand that such laws differ from state to state, and even from time to time as laws are changed, and thus any legal use of the term is understood to require new research practically any time it comes up.\"\"\\n\\n This is just a proposal off the top of my head and after reading what some of the other editors have said. Any coments? (BTW, I came to this article ecause I was looking at the list of disputed articles and I wondered why this one was on the list.)  \"'\n",
      " b'Article Vegetarianism in Sikhism\\n\\nHi fellow editor, your input to try and get these quotes in a legible format to suit wikipedia would be most welcome. I am keen not to lose this valuable information and research, but at the same time present it in a format that works in wikipedia. Thanks'\n",
      " b\"Don't jump on the vandalize Parma bandwagon.  If you have something legitimate to contribute good, but we get enough scumbags mindlessly trying to mass delete stuff from that article as it is.  Grow up, kids!\"\n",
      " b'Wholly agree with Surtsicna - should be removed immediately. It is pointless and of no informative value to mention it without authoritative source.'\n",
      " b'\"\\nYes, both countries claim the regions controlled by the other as a part of the one in their own control.  (talk) \"'\n",
      " b\"Firstly, Montanabw, there is no such thing as Equus caballus. That is a domesticated animal. The proper name is Equus ferus caballus - unless domesticated Horses somehow come from Zebras or Asses... Also, there is no consensus that Equus ferus ever set foot on the North American continent, though I personally believe Equus lambei may be a subspecy of Equus ferus. Thirdly, and most importantly, and I hope EVERYONE is listening here when I say this, Equus ferus caballus, the domesticated Horse IS NO MORE native to the North American west than Chihuahuas are to the Canadian tundra. Domestic forms are native NOWHERE. Period. The domestic Horse is RADICALLY different from it's wild ancestor. And Dysmorodrepanis, the reason all the Equine articles are so Horse-centric is because a very large number of vociferous (and outright foolish) people are unhealthily obsessed with horses. Unfortunately, many of these people also think themselves expert enough to declare a domestic animal native to a continent it never inhabited simply because they like to watch them run. Seriously, that's all it is. They like looking at them. It's certainly not an environmental issue. Horses are wildly destructive to their surroundings. They eat more than cattle! And an obscene amount more than the native Pronghorn (which, by the way doesn't trample its food to death like the Mustangs do with they're enormous, heavy-stepping hooves). The only argument the Mustang and Burro worshippers have to use (and they milk it good, let me tell ya) is the similarity of Equus lambei to Equus ferus. But, Equus lambei has not been proven to be synonymous with Equus ferus (though it is a possibility), and even if it were it would be more closely related, by far, to Przewalski's Horse than to Mustangs! E. lambei was tiny! It was like four feet tall at the shoulders! And all the other North American Equids are pretty well-known to not be synonyms with Equus ferus (including E. caballus). Not by a long shot. This is why the Horse Evolution page (and every other page dealing with equines) has been changed back and forth so many times. The people who know what the heck they're talking about try to add useful information and correct blatant lies or grievous mistakes and the people who like pretty ponies go back and try to convince the world that Spanish horses have roamed every continent including Antarctica, Mars and the Sun since before Dinosaurs walked on two feet. I made the ridiculous mistake of trying to add factual information to the Mustang article and, if I remember correctly, it was changed WITHIN THE HOUR. The person doing the changing even removed the scientific names I inserted! The Mustang article has absolutely no indication of what specy the Mustang belongs to now! I swear this endless struggle between the My Little Ponyites and REAL BIOLOGISTS is like the Evolution vs. creationism argument, only dumber. Like I said, these people aren't calling for us to turn our rotweillers loose into the nearest forest, but why not? I mean, it's the same specy as the Gray Wolf. Domestication doesn't matter, if you listen to these people. If that's the case then why aren't we restocking mature Oak forests with farm raised white turkeys? I mean, it's the same specy, after all. Oh. And this is my favourite. Where Wild Asses are actually native they're critically endangered. But I have not read ONE WORD from the Cult of the Mustang and Burro about saving them from ACTUAL extinction, but get this, they want to have the Mustangs and Burros in America declared endangered species. How's that for mentally inept and savagely hypocritical?\"\n",
      " b'if you do not stop, the wikapidea nijas will come to your house and kill you'\n",
      " b'\"== Courtlandt Gross - Lockheed ==\\n\\nHi there, I wasn\\'t sure what you meant by \"\"... subject is in your list of notables ...\"\". Which list is this? About copyright, we cannot normally accept material just copied from other sources. If you want to write it in your own words and resubmit that would probably be fine. Any other questions, please ask.   \"'\n",
      " b'WikiProject Films January 2009 Newsletter \\nThe January 2009 issue of the WikiProject Films newsletter has been published.  You may read the newsletter, change the format in which future issues will be delivered to you, or unsubscribe from this notification by following the link.  Thank you and happy editing!'\n",
      " b'\\xe2\\x80\\x94The preceding unsigned comment was added by  (talk \\xe2\\x80\\xa2 contribs).\\n\\nYou already know WP:EL, so you obviously must be joking... Stop pushing for your site.'\n",
      " b'stackjones \\n\\nplease stop editing factual material on stack jones page.\\n\\nyou are removing well-known and factual information  information that is cited and having several wikipedia pages referring to the same material.'\n",
      " b'\"\\nObservation only:  article creation date 2007.- Sinneed \"'\n",
      " b'Name change\\nThe name of the article should be changed to Narsinh along with all the terms inside , Narsinh is the correct way of pronouncing the term. Narsimha is the wrong spelling , the wrong spelling was popularized because of some British authors used the incorrect spelling in late 19 century'\n",
      " b'\"\\n\\n Comments from RHB \\n\\nI am approaching this as someone who knows very little about the subject. I will give some high-level comments mainly on structure and content. There are copyediting and prose issues as well, but it is probably worthwhile to tackle the general problems before going into specifics. Before I start, one general point that you will see often in my comments is that there are at times new subjects that are suddenly introduced. Although wikilinks help, a clause or a few words of explanation would smooth the flow of reading for a person not familiar with the subject.\\n\\nBackground to the mission\\nThis section seems a little long relative to the rest of the article. Unless there is a significant expansion planned for the rest of the article, I would recommend reducing this section. There are small details that do not add very much to the Augustine story, e.g., the origin of St Martin\\xe2\\x80\\x99s Church, the fair-haired slaves theory, the pope writing to various kings.\\nBede is suddenly introduced without explanation.\\n\\nArrival and first efforts\\nThe mission turning back to Rome is not explained. Is there a significance to what happened?\\nIt says \\xe2\\x80\\x9c\\xe2\\x80\\xa6on the one hand\\xe2\\x80\\xa6 on the other hand\\xe2\\x80\\xa6\\xe2\\x80\\x9d but the two items mentioned do not seem to be in opposition as expected when this phrasing is used.\\nAugustine established first at Canterbury. Since he was the originator, it might be good to give a reason why he chose the location.\\nThe Archbishop of Arles is suddenly introduced. Who is he? Was he based in Arles (in modern-day France) or in Kent? The existence of an Archbishop implies a significant Christian population existing on British soil. This then brings more questions to mind.\\nIt says \"\"That Christmas\\xe2\\x80\\xa6\"\". But what year is that?\\nThe king became a saint after his death, but the sentence may be in the wrong place. Did the king die shortly after Augustine\\'s arrival?\\nIn the same paragraph, some information of the existence of Christians before Augustine\\'s arrival is given. This info should go before the discussion of Augustine\\'s arrival.\\nMellitus and Justus are suddenly introduced without explanation.\\nThe sentence \"\"A theory by the historian S. Brechter\\xe2\\x80\\xa6\"\" is either a run-on sentence or is incomplete.\\n\\nAdditional work\\nAfter the first sentence describing the two episcopal sees, there is a sudden jump to after 1066 and a discussion of a cathedral. How are they linked? Also what cathedral is it? The description of the archeology seems out of place in the \"\"Additional work\"\" section. Is it meant to show that Augustine managed to build new churches?\\nIf Aethelbert was only the King of Kent, how was he able to summon bishops outside his realm?\\nThere is a sudden introduction of the tonsure.\\n\\nFurther success\\nConcerning \"\"temples and usages\"\" is that \"\"temples and their use\"\"? The \"\"former\\xe2\\x80\\xa6 latter\"\" construct does not work very well here.\\nConcerning the quote \"\"whoever wishes\\xe2\\x80\\xa6\"\", who said that?\\n\\nI would recommend reading the article out loud. I think you will find some sentence structures that seem a bit complex or difficult to understand. Following the corrections, a good copyedit/prose check is needed. I give as an example, the sentence \"\"As to why Pope Gregory\\xe2\\x80\\xa6\"\" could be made better as in \"\"Nothing is mentioned in the sources on why Pope Gregory chose a monk to head the mission\"\".\\n\\nI hope this has been helpful.   \"'\n",
      " b'\"\\n You have listed as references on this article a collection of four people at Alliant University, presumably students / clients of Dr Corona in her capacity as director at the Office of International Students and Students Scholars at AU. While your admiration for Dr Corona is laudable, Wikipedia isn\\'t looking for personal references, we\\'re looking for citations to published material about Dr Corona. We need to be able to verify that the information about her is correct, and the only way we can do that is to look to published sources where she has been discussed. If no such sources exist, the article will be deleted. If such sources do exist, please add them to the article. ChatMe!ReadMe!! \"'\n",
      " b\". So while locally the O'Donovan was a petty king with his wand, his realm was not extensive. Outside of Carbery he and his sept were only seen as vassals of the MacCarthy Reagh for three centuries\"\n",
      " b'Reply.\\nCheck the dates, I was blocked for that incident for a week. -'\n",
      " b'Link Building strategies \\n\\nLink building is the practice of getting other sites to link back to your website. This can often be done using a wide variety of strategies, such as:\\n\\nAsking for a link\\nGiving away content or tools\\nWidget development\\nSocial media campaigns\\nPurchasing links and more\\xe2\\x80\\xa6.\\nBut first, let\\xe2\\x80\\x99s start with the basic theories\\xe2\\x80\\xa6\\n\\n* Why Link Building Matters\\n\\nWhenever any user enters a query into a search engine, the search engine needs to determine how to return the best results. How? There are two key steps:\\nFigure out which pages on the web are related in any way to the query\\nEvaluate which of the pages that relate to the query are the most important\\nEach link to a web page is seen as a vote for that web page.\\nIn simple terms, if there are two pages that are equally relevant to a given search query, the page with the better inbound link profile will rank higher than the other page (being all other factors equal).\\nHence, the need of Link Building!\\n\\n*How Search Engines Evaluate Links\\n\\nEach link to a web page is a vote for that web page.\\nThat implies the higher the PR, the more the value of that vote. This is partially true. But, two votes may not have equal weight even if they are from same PR page.\\nValue of vote depends on \\xe2\\x80\\x93 Relevance and Authority\\nNow let\\xe2\\x80\\x99s take a deeper look at these factors\\xe2\\x80\\xa6\\n\\n* Relevance Factor\\n\\nTheme of the linking website\\nPurpose of the linking website\\nTopic of the linking page'\n",
      " b'Guia Circuit and Bucharest Ring.'\n",
      " b'I hope that you understand the artful concept of diplomacy, because Wikipedia is a community of collaboration to compile a NPOV presentation of all thingsincluding those Scottish topics you lurk on and fight over.'\n",
      " b'. Also quit touching little boys'\n",
      " b'\"\\nSeriously, which 100% complete ass had the 100% completely idiotic idea to call this article \"\"Death of Neda Agha-Soltan\"\"???  You call it by her name and indicate that she became famous for the manner of her death.  Doh. 74.233.165.176  \"'\n",
      " b'oink oink oink, freaking pig'\n",
      " b\"Hello!! It's Lazar again.  I just listened to the same bible passage in Macedonian (standard) and in Bulgarian (standard).  I am a serb and have concluded yes, macedonian is bulgarian.  However it is heavily serbinized.  -Lazar\"\n",
      " b\"not appropriate at all. It is about his racist's views where the Arabs are mentioned,  too. So, putting back Historical findings about his political ideology\"\n",
      " b\"I think you're is right, but to prevent edit wars, maybe you can post a rewrited version on this talk page to see how people reacts to your changes.\"\n",
      " b'The Federal Police is on to you! \\n\\nYou racist anti-Australian! I WILL get the Federal Police on you to put you in prison! AUSSIE PRIDE!58.178.146.217'\n",
      " b'\"\\n\\nCategory:Songs from We Will Rock You (musical)\\n\\n:Category:Songs from We Will Rock You (musical), which you created, has been nominated for possible deletion, merging, or renaming. If you would like to participate in the discussion, you are invited to add your comments at the category\\'s entry on the Categories for discussion page. Thank you. StarcheerspeaksnewslostwarsTalk to me \"']\n",
      "-------------------------------------------------------------------------------------------------------------------------------\n",
      "toxic               : [0 0 0 1 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 1 0]\n",
      "-------------------------------------------------------------------------------------------------------------------------------\n",
      "===============================================================================================================================\n",
      "\n",
      "label               : [ 46558  47445 134163 124388 111874  43030  56738  71780  42069  77382\n",
      " 157241  31258  35542  78962  40586  24588  57904  70617 143969 149488\n",
      " 150628  84530  96797 113387  58258  44115  75306  15168 142253 158789\n",
      " 141011  38612]\n"
     ]
    }
   ],
   "source": [
    "for batch, label in toxic_comments_csv_ds_test.take(1):\n",
    "    for key, value in batch.items():\n",
    "        print(f\"{key:20s}: {value}\")\n",
    "        print('-'*127)\n",
    "    print('='*127)\n",
    "    print('')\n",
    "    print(f\"{'label':20s}: {label}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "125d80bc",
   "metadata": {},
   "source": [
    "## Загрузка моделей с TensorFlow HUB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "a5927d84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BERT model selected           : https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-4_H-512_A-8/1\n",
      "Preprocess model auto-selected: https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3\n"
     ]
    }
   ],
   "source": [
    "#@title Choose a BERT model to fine-tune\n",
    "\n",
    "bert_model_name = 'small_bert/bert_en_uncased_L-4_H-512_A-8'  #@param [\"bert_en_uncased_L-12_H-768_A-12\", \"bert_en_cased_L-12_H-768_A-12\", \"bert_multi_cased_L-12_H-768_A-12\", \"small_bert/bert_en_uncased_L-2_H-128_A-2\", \"small_bert/bert_en_uncased_L-2_H-256_A-4\", \"small_bert/bert_en_uncased_L-2_H-512_A-8\", \"small_bert/bert_en_uncased_L-2_H-768_A-12\", \"small_bert/bert_en_uncased_L-4_H-128_A-2\", \"small_bert/bert_en_uncased_L-4_H-256_A-4\", \"small_bert/bert_en_uncased_L-4_H-512_A-8\", \"small_bert/bert_en_uncased_L-4_H-768_A-12\", \"small_bert/bert_en_uncased_L-6_H-128_A-2\", \"small_bert/bert_en_uncased_L-6_H-256_A-4\", \"small_bert/bert_en_uncased_L-6_H-512_A-8\", \"small_bert/bert_en_uncased_L-6_H-768_A-12\", \"small_bert/bert_en_uncased_L-8_H-128_A-2\", \"small_bert/bert_en_uncased_L-8_H-256_A-4\", \"small_bert/bert_en_uncased_L-8_H-512_A-8\", \"small_bert/bert_en_uncased_L-8_H-768_A-12\", \"small_bert/bert_en_uncased_L-10_H-128_A-2\", \"small_bert/bert_en_uncased_L-10_H-256_A-4\", \"small_bert/bert_en_uncased_L-10_H-512_A-8\", \"small_bert/bert_en_uncased_L-10_H-768_A-12\", \"small_bert/bert_en_uncased_L-12_H-128_A-2\", \"small_bert/bert_en_uncased_L-12_H-256_A-4\", \"small_bert/bert_en_uncased_L-12_H-512_A-8\", \"small_bert/bert_en_uncased_L-12_H-768_A-12\", \"albert_en_base\", \"electra_small\", \"electra_base\", \"experts_pubmed\", \"experts_wiki_books\", \"talking-heads_base\"]\n",
    "\n",
    "map_name_to_handle = {\n",
    "    'bert_en_uncased_L-12_H-768_A-12':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_L-12_H-768_A-12/3',\n",
    "    'bert_en_cased_L-12_H-768_A-12':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_cased_L-12_H-768_A-12/3',\n",
    "    'bert_multi_cased_L-12_H-768_A-12':\n",
    "        'https://tfhub.dev/tensorflow/bert_multi_cased_L-12_H-768_A-12/3',\n",
    "    'small_bert/bert_en_uncased_L-2_H-128_A-2':\n",
    "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-2_H-128_A-2/1',\n",
    "    'small_bert/bert_en_uncased_L-2_H-256_A-4':\n",
    "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-2_H-256_A-4/1',\n",
    "    'small_bert/bert_en_uncased_L-2_H-512_A-8':\n",
    "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-2_H-512_A-8/1',\n",
    "    'small_bert/bert_en_uncased_L-2_H-768_A-12':\n",
    "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-2_H-768_A-12/1',\n",
    "    'small_bert/bert_en_uncased_L-4_H-128_A-2':\n",
    "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-4_H-128_A-2/1',\n",
    "    'small_bert/bert_en_uncased_L-4_H-256_A-4':\n",
    "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-4_H-256_A-4/1',\n",
    "    'small_bert/bert_en_uncased_L-4_H-512_A-8':\n",
    "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-4_H-512_A-8/1',\n",
    "    'small_bert/bert_en_uncased_L-4_H-768_A-12':\n",
    "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-4_H-768_A-12/1',\n",
    "    'small_bert/bert_en_uncased_L-6_H-128_A-2':\n",
    "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-6_H-128_A-2/1',\n",
    "    'small_bert/bert_en_uncased_L-6_H-256_A-4':\n",
    "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-6_H-256_A-4/1',\n",
    "    'small_bert/bert_en_uncased_L-6_H-512_A-8':\n",
    "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-6_H-512_A-8/1',\n",
    "    'small_bert/bert_en_uncased_L-6_H-768_A-12':\n",
    "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-6_H-768_A-12/1',\n",
    "    'small_bert/bert_en_uncased_L-8_H-128_A-2':\n",
    "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-8_H-128_A-2/1',\n",
    "    'small_bert/bert_en_uncased_L-8_H-256_A-4':\n",
    "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-8_H-256_A-4/1',\n",
    "    'small_bert/bert_en_uncased_L-8_H-512_A-8':\n",
    "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-8_H-512_A-8/1',\n",
    "    'small_bert/bert_en_uncased_L-8_H-768_A-12':\n",
    "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-8_H-768_A-12/1',\n",
    "    'small_bert/bert_en_uncased_L-10_H-128_A-2':\n",
    "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-10_H-128_A-2/1',\n",
    "    'small_bert/bert_en_uncased_L-10_H-256_A-4':\n",
    "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-10_H-256_A-4/1',\n",
    "    'small_bert/bert_en_uncased_L-10_H-512_A-8':\n",
    "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-10_H-512_A-8/1',\n",
    "    'small_bert/bert_en_uncased_L-10_H-768_A-12':\n",
    "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-10_H-768_A-12/1',\n",
    "    'small_bert/bert_en_uncased_L-12_H-128_A-2':\n",
    "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-12_H-128_A-2/1',\n",
    "    'small_bert/bert_en_uncased_L-12_H-256_A-4':\n",
    "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-12_H-256_A-4/1',\n",
    "    'small_bert/bert_en_uncased_L-12_H-512_A-8':\n",
    "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-12_H-512_A-8/1',\n",
    "    'small_bert/bert_en_uncased_L-12_H-768_A-12':\n",
    "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-12_H-768_A-12/1',\n",
    "    'albert_en_base':\n",
    "        'https://tfhub.dev/tensorflow/albert_en_base/2',\n",
    "    'electra_small':\n",
    "        'https://tfhub.dev/google/electra_small/2',\n",
    "    'electra_base':\n",
    "        'https://tfhub.dev/google/electra_base/2',\n",
    "    'experts_pubmed':\n",
    "        'https://tfhub.dev/google/experts/bert/pubmed/2',\n",
    "    'experts_wiki_books':\n",
    "        'https://tfhub.dev/google/experts/bert/wiki_books/2',\n",
    "    'talking-heads_base':\n",
    "        'https://tfhub.dev/tensorflow/talkheads_ggelu_bert_en_base/1',\n",
    "}\n",
    "\n",
    "map_model_to_preprocess = {\n",
    "    'bert_en_uncased_L-12_H-768_A-12':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "    'bert_en_cased_L-12_H-768_A-12':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_cased_preprocess/3',\n",
    "    'small_bert/bert_en_uncased_L-2_H-128_A-2':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "    'small_bert/bert_en_uncased_L-2_H-256_A-4':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "    'small_bert/bert_en_uncased_L-2_H-512_A-8':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "    'small_bert/bert_en_uncased_L-2_H-768_A-12':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "    'small_bert/bert_en_uncased_L-4_H-128_A-2':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "    'small_bert/bert_en_uncased_L-4_H-256_A-4':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "    'small_bert/bert_en_uncased_L-4_H-512_A-8':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "    'small_bert/bert_en_uncased_L-4_H-768_A-12':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "    'small_bert/bert_en_uncased_L-6_H-128_A-2':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "    'small_bert/bert_en_uncased_L-6_H-256_A-4':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "    'small_bert/bert_en_uncased_L-6_H-512_A-8':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "    'small_bert/bert_en_uncased_L-6_H-768_A-12':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "    'small_bert/bert_en_uncased_L-8_H-128_A-2':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "    'small_bert/bert_en_uncased_L-8_H-256_A-4':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "    'small_bert/bert_en_uncased_L-8_H-512_A-8':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "    'small_bert/bert_en_uncased_L-8_H-768_A-12':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "    'small_bert/bert_en_uncased_L-10_H-128_A-2':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "    'small_bert/bert_en_uncased_L-10_H-256_A-4':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "    'small_bert/bert_en_uncased_L-10_H-512_A-8':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "    'small_bert/bert_en_uncased_L-10_H-768_A-12':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "    'small_bert/bert_en_uncased_L-12_H-128_A-2':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "    'small_bert/bert_en_uncased_L-12_H-256_A-4':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "    'small_bert/bert_en_uncased_L-12_H-512_A-8':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "    'small_bert/bert_en_uncased_L-12_H-768_A-12':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "    'bert_multi_cased_L-12_H-768_A-12':\n",
    "        'https://tfhub.dev/tensorflow/bert_multi_cased_preprocess/3',\n",
    "    'albert_en_base':\n",
    "        'https://tfhub.dev/tensorflow/albert_en_preprocess/3',\n",
    "    'electra_small':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "    'electra_base':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "    'experts_pubmed':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "    'experts_wiki_books':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "    'talking-heads_base':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "}\n",
    "\n",
    "tfhub_handle_encoder = map_name_to_handle[bert_model_name]\n",
    "tfhub_handle_preprocess = map_model_to_preprocess[bert_model_name]\n",
    "\n",
    "print(f'BERT model selected           : {tfhub_handle_encoder}')\n",
    "print(f'Preprocess model auto-selected: {tfhub_handle_preprocess}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d24a9399",
   "metadata": {},
   "source": [
    "## Модель предварительной обработки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "1e7d636e",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "Op type not registered 'CaseFoldUTF8' in binary running on ALEXEY. Make sure the Op and Kernel are registered in the binary running in this process. Note that if you are loading a saved graph which used ops from tf.contrib, accessing (e.g.) `tf.contrib.resampler` should be done before importing the graph, as contrib ops are lazily registered when the module is first accessed.\n You may be trying to load on a different device from the computational device. Consider setting the `experimental_io_device` option in `tf.saved_model.LoadOptions` to the io_device such as '/job:localhost'.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32mD:\\Program File\\Anaconda\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py:4199\u001b[0m, in \u001b[0;36mGraph._get_op_def\u001b[1;34m(self, type)\u001b[0m\n\u001b[0;32m   4198\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 4199\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_op_def_cache\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mtype\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[0;32m   4200\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m:\n",
      "\u001b[1;31mKeyError\u001b[0m: 'CaseFoldUTF8'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mNotFoundError\u001b[0m                             Traceback (most recent call last)",
      "File \u001b[1;32mD:\\Program File\\Anaconda\\lib\\site-packages\\tensorflow\\python\\saved_model\\load.py:958\u001b[0m, in \u001b[0;36mload_partial\u001b[1;34m(export_dir, filters, tags, options)\u001b[0m\n\u001b[0;32m    957\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 958\u001b[0m   loader \u001b[38;5;241m=\u001b[39m \u001b[43mLoader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobject_graph_proto\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msaved_model_proto\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexport_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    959\u001b[0m \u001b[43m                  \u001b[49m\u001b[43mckpt_options\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfilters\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    960\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m errors\u001b[38;5;241m.\u001b[39mNotFoundError \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[1;32mD:\\Program File\\Anaconda\\lib\\site-packages\\tensorflow\\python\\saved_model\\load.py:154\u001b[0m, in \u001b[0;36mLoader.__init__\u001b[1;34m(self, object_graph_proto, saved_model_proto, export_dir, ckpt_options, save_options, filters)\u001b[0m\n\u001b[0;32m    152\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_export_dir \u001b[38;5;241m=\u001b[39m export_dir\n\u001b[0;32m    153\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_concrete_functions \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m--> 154\u001b[0m     \u001b[43mfunction_deserialization\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_function_def_library\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    155\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlibrary\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmeta_graph\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgraph_def\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlibrary\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    156\u001b[0m \u001b[43m        \u001b[49m\u001b[43msaved_object_graph\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_proto\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    157\u001b[0m \u001b[43m        \u001b[49m\u001b[43mwrapper_function\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_WrapperFunction\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m    158\u001b[0m \u001b[38;5;66;03m# Store a set of all concrete functions that have been set up with\u001b[39;00m\n\u001b[0;32m    159\u001b[0m \u001b[38;5;66;03m# captures.\u001b[39;00m\n",
      "File \u001b[1;32mD:\\Program File\\Anaconda\\lib\\site-packages\\tensorflow\\python\\saved_model\\function_deserialization.py:416\u001b[0m, in \u001b[0;36mload_function_def_library\u001b[1;34m(library, saved_object_graph, load_shared_name_suffix, wrapper_function)\u001b[0m\n\u001b[0;32m    415\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m graph\u001b[38;5;241m.\u001b[39mas_default():\n\u001b[1;32m--> 416\u001b[0m   func_graph \u001b[38;5;241m=\u001b[39m \u001b[43mfunction_def_lib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction_def_to_graph\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    417\u001b[0m \u001b[43m      \u001b[49m\u001b[43mfdef\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    418\u001b[0m \u001b[43m      \u001b[49m\u001b[43mstructured_input_signature\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstructured_input_signature\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    419\u001b[0m \u001b[43m      \u001b[49m\u001b[43mstructured_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstructured_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    420\u001b[0m \u001b[38;5;66;03m# Restores gradients for function-call ops (not the same as ops that use\u001b[39;00m\n\u001b[0;32m    421\u001b[0m \u001b[38;5;66;03m# custom gradients)\u001b[39;00m\n",
      "File \u001b[1;32mD:\\Program File\\Anaconda\\lib\\site-packages\\tensorflow\\python\\framework\\function_def_to_graph.py:82\u001b[0m, in \u001b[0;36mfunction_def_to_graph\u001b[1;34m(fdef, structured_input_signature, structured_outputs, input_shapes)\u001b[0m\n\u001b[0;32m     80\u001b[0m         input_shapes\u001b[38;5;241m.\u001b[39mappend(input_shape)\n\u001b[1;32m---> 82\u001b[0m graph_def, nested_to_flat_tensor_name \u001b[38;5;241m=\u001b[39m \u001b[43mfunction_def_to_graph_def\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     83\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfdef\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_shapes\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     85\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m func_graph\u001b[38;5;241m.\u001b[39mas_default():\n\u001b[0;32m     86\u001b[0m   \u001b[38;5;66;03m# Add all function nodes to the graph.\u001b[39;00m\n",
      "File \u001b[1;32mD:\\Program File\\Anaconda\\lib\\site-packages\\tensorflow\\python\\framework\\function_def_to_graph.py:252\u001b[0m, in \u001b[0;36mfunction_def_to_graph_def\u001b[1;34m(fdef, input_shapes)\u001b[0m\n\u001b[0;32m    251\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 252\u001b[0m   op_def \u001b[38;5;241m=\u001b[39m \u001b[43mdefault_graph\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_op_def\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnode_def\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mop\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[0;32m    254\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m attr \u001b[38;5;129;01min\u001b[39;00m op_def\u001b[38;5;241m.\u001b[39mattr:\n",
      "File \u001b[1;32mD:\\Program File\\Anaconda\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py:4203\u001b[0m, in \u001b[0;36mGraph._get_op_def\u001b[1;34m(self, type)\u001b[0m\n\u001b[0;32m   4202\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_c_graph\u001b[38;5;241m.\u001b[39mget() \u001b[38;5;28;01mas\u001b[39;00m c_graph:\n\u001b[1;32m-> 4203\u001b[0m   \u001b[43mpywrap_tf_session\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTF_GraphGetOpDef\u001b[49m\u001b[43m(\u001b[49m\u001b[43mc_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcompat\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mas_bytes\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mtype\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4204\u001b[0m \u001b[43m                                     \u001b[49m\u001b[43mbuf\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   4205\u001b[0m data \u001b[38;5;241m=\u001b[39m pywrap_tf_session\u001b[38;5;241m.\u001b[39mTF_GetBuffer(buf)\n",
      "\u001b[1;31mNotFoundError\u001b[0m: Op type not registered 'CaseFoldUTF8' in binary running on ALEXEY. Make sure the Op and Kernel are registered in the binary running in this process. Note that if you are loading a saved graph which used ops from tf.contrib, accessing (e.g.) `tf.contrib.resampler` should be done before importing the graph, as contrib ops are lazily registered when the module is first accessed.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[90], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m bert_preprocess_model \u001b[38;5;241m=\u001b[39m \u001b[43mhub\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mKerasLayer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtfhub_handle_preprocess\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mD:\\Program File\\Anaconda\\lib\\site-packages\\tensorflow_hub\\keras_layer.py:157\u001b[0m, in \u001b[0;36mKerasLayer.__init__\u001b[1;34m(self, handle, trainable, arguments, _sentinel, tags, signature, signature_outputs_as_dict, output_key, output_shape, load_options, **kwargs)\u001b[0m\n\u001b[0;32m    153\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_output_shape \u001b[38;5;241m=\u001b[39m data_structures\u001b[38;5;241m.\u001b[39mNoDependency(\n\u001b[0;32m    154\u001b[0m       _convert_nest_to_shapes(output_shape))\n\u001b[0;32m    156\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_load_options \u001b[38;5;241m=\u001b[39m load_options\n\u001b[1;32m--> 157\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_func \u001b[38;5;241m=\u001b[39m \u001b[43mload_module\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtags\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_load_options\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    158\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_is_hub_module_v1 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_func, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_is_hub_module_v1\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m    160\u001b[0m \u001b[38;5;66;03m# Update with the defaults when using legacy TF1 Hub format.\u001b[39;00m\n",
      "File \u001b[1;32mD:\\Program File\\Anaconda\\lib\\site-packages\\tensorflow_hub\\keras_layer.py:459\u001b[0m, in \u001b[0;36mload_module\u001b[1;34m(handle, tags, load_options)\u001b[0m\n\u001b[0;32m    457\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m:  \u001b[38;5;66;03m# Expected before TF2.4.\u001b[39;00m\n\u001b[0;32m    458\u001b[0m       set_load_options \u001b[38;5;241m=\u001b[39m load_options\n\u001b[1;32m--> 459\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmodule_v2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtags\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtags\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mset_load_options\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mD:\\Program File\\Anaconda\\lib\\site-packages\\tensorflow_hub\\module_v2.py:120\u001b[0m, in \u001b[0;36mload\u001b[1;34m(handle, tags, options)\u001b[0m\n\u001b[0;32m    117\u001b[0m   obj \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mcompat\u001b[38;5;241m.\u001b[39mv1\u001b[38;5;241m.\u001b[39msaved_model\u001b[38;5;241m.\u001b[39mload_v2(\n\u001b[0;32m    118\u001b[0m       module_path, tags\u001b[38;5;241m=\u001b[39mtags, options\u001b[38;5;241m=\u001b[39moptions)\n\u001b[0;32m    119\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 120\u001b[0m   obj \u001b[38;5;241m=\u001b[39m \u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompat\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mv1\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msaved_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_v2\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodule_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtags\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtags\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    121\u001b[0m obj\u001b[38;5;241m.\u001b[39m_is_hub_module_v1 \u001b[38;5;241m=\u001b[39m is_hub_module_v1  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[0;32m    122\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m obj\n",
      "File \u001b[1;32mD:\\Program File\\Anaconda\\lib\\site-packages\\tensorflow\\python\\saved_model\\load.py:828\u001b[0m, in \u001b[0;36mload\u001b[1;34m(export_dir, tags, options)\u001b[0m\n\u001b[0;32m    826\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(export_dir, os\u001b[38;5;241m.\u001b[39mPathLike):\n\u001b[0;32m    827\u001b[0m   export_dir \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mfspath(export_dir)\n\u001b[1;32m--> 828\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mload_partial\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexport_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtags\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mroot\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m    829\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[1;32mD:\\Program File\\Anaconda\\lib\\site-packages\\tensorflow\\python\\saved_model\\load.py:961\u001b[0m, in \u001b[0;36mload_partial\u001b[1;34m(export_dir, filters, tags, options)\u001b[0m\n\u001b[0;32m    958\u001b[0m   loader \u001b[38;5;241m=\u001b[39m Loader(object_graph_proto, saved_model_proto, export_dir,\n\u001b[0;32m    959\u001b[0m                   ckpt_options, options, filters)\n\u001b[0;32m    960\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m errors\u001b[38;5;241m.\u001b[39mNotFoundError \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m--> 961\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mFileNotFoundError\u001b[39;00m(\n\u001b[0;32m    962\u001b[0m       \u001b[38;5;28mstr\u001b[39m(err) \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m You may be trying to load on a different device \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    963\u001b[0m       \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfrom the computational device. Consider setting the \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    964\u001b[0m       \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`experimental_io_device` option in `tf.saved_model.LoadOptions` \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    965\u001b[0m       \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mto the io_device such as \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/job:localhost\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    966\u001b[0m root \u001b[38;5;241m=\u001b[39m loader\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m    967\u001b[0m root\u001b[38;5;241m.\u001b[39mgraph_debug_info \u001b[38;5;241m=\u001b[39m loader\u001b[38;5;241m.\u001b[39madjust_debug_info_func_names(debug_info)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: Op type not registered 'CaseFoldUTF8' in binary running on ALEXEY. Make sure the Op and Kernel are registered in the binary running in this process. Note that if you are loading a saved graph which used ops from tf.contrib, accessing (e.g.) `tf.contrib.resampler` should be done before importing the graph, as contrib ops are lazily registered when the module is first accessed.\n You may be trying to load on a different device from the computational device. Consider setting the `experimental_io_device` option in `tf.saved_model.LoadOptions` to the io_device such as '/job:localhost'."
     ]
    }
   ],
   "source": [
    "bert_preprocess_model = hub.KerasLayer(tfhub_handle_preprocess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "4cb52c7d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"That makes no sense. You don't play MapleStory through Internet Explorer. Sure, the website can only be accessible through IE (well, you can access it through Firefox as well if you know what to do), but it's not really part of the game.\""
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "cbf4b770",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'bert_preprocess_model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[47], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m text_test \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(corpus_train[\u001b[38;5;241m0\u001b[39m])\n\u001b[1;32m----> 2\u001b[0m text_preprocessed \u001b[38;5;241m=\u001b[39m \u001b[43mbert_preprocess_model\u001b[49m(text_test)\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mKeys       : \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlist\u001b[39m(text_preprocessed\u001b[38;5;241m.\u001b[39mkeys())\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mShape      : \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtext_preprocessed[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minput_word_ids\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'bert_preprocess_model' is not defined"
     ]
    }
   ],
   "source": [
    "text_test = list(corpus_train[0])\n",
    "text_preprocessed = bert_preprocess_model(text_test)\n",
    "\n",
    "print(f'Keys       : {list(text_preprocessed.keys())}')\n",
    "print(f'Shape      : {text_preprocessed[\"input_word_ids\"].shape}')\n",
    "print(f'Word Ids   : {text_preprocessed[\"input_word_ids\"][0, :12]}')\n",
    "print(f'Input Mask : {text_preprocessed[\"input_mask\"][0, :12]}')\n",
    "print(f'Type Ids   : {text_preprocessed[\"input_type_ids\"][0, :12]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aede893e",
   "metadata": {},
   "source": [
    "### Возвращаемые значения"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f46516fc",
   "metadata": {},
   "source": [
    "Прежде чем внедрять BERT в вашу собственную модель, нужно сначала взглянуть на ее выходные данные. \n",
    "\n",
    "Мы загрузили его из TF Hub, и теперь увидим возвращаемые значения."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 447,
   "id": "4a9283a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_model = hub.KerasLayer(tfhub_handle_encoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 448,
   "id": "dafd493e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded BERT: https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-4_H-512_A-8/1\n",
      "Pooled Outputs Shape:(463, 512)\n",
      "Pooled Outputs Values:[ 0.964834   -0.17843105 -0.25604504 -0.08633736  0.06525536  0.96364266\n",
      "  0.76323825 -0.8259036  -0.25786063 -0.9997027   0.15350132 -0.99833673]\n",
      "Sequence Outputs Shape:(463, 128, 512)\n",
      "Sequence Outputs Values:[[ 1.1880465   0.16548514  0.52010137 ... -1.3935456   0.72548085\n",
      "   0.4851817 ]\n",
      " [ 1.8258715   0.6981835  -0.92007947 ...  0.02137677  1.1609669\n",
      "   0.11297412]\n",
      " [ 1.3568974  -0.37145764  1.0243483  ... -0.6833948   0.30857855\n",
      "   0.20199293]\n",
      " ...\n",
      " [ 0.8787285  -0.02032542 -0.4496386  ... -0.18110166  0.92780066\n",
      "   0.22329672]\n",
      " [ 0.87346816  0.26692882 -0.26071578 ... -0.20293932  1.0134312\n",
      "   0.07956394]\n",
      " [ 0.87515575  0.36114353 -0.38098806 ... -0.17099996  0.94220555\n",
      "   0.06431089]]\n"
     ]
    }
   ],
   "source": [
    "bert_results = bert_model(text_preprocessed)\n",
    "\n",
    "print(f'Loaded BERT: {tfhub_handle_encoder}')\n",
    "print(f'Pooled Outputs Shape:{bert_results[\"pooled_output\"].shape}')\n",
    "print(f'Pooled Outputs Values:{bert_results[\"pooled_output\"][0, :12]}')\n",
    "print(f'Sequence Outputs Shape:{bert_results[\"sequence_output\"].shape}')\n",
    "print(f'Sequence Outputs Values:{bert_results[\"sequence_output\"][0, :12]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aebb57e9",
   "metadata": {},
   "source": [
    "**ЛУЧШИЕ модели** возвращают карту с 3 важными ключами: `pooled_output`, `sequence_output`, `encoder_outputs`:\n",
    "\n",
    "`pooled_output` представляет каждую входную последовательность в целом. Форма - `[batch_size, H]`. Мы можем рассматривать это как встраивание для всего обзора фильма.\n",
    "\n",
    "`sequence_output` представляет каждый входной токен в контексте. Форма имеет вид `[batch_size, seq_length, H]`. Мы можем думать об этом как о контекстуальном встраивании для каждого токена в обзоре фильма.\n",
    "\n",
    "`encoder_outputs` - это промежуточные активации блоков `L`-трансформатора. выходные данные `[\"encoder_outputs\"][i]` - это тензор формы `[batch_size, seq_length, 1024]` с выходами i-го блока преобразования, для `0 <= i < L`. Последнее значение списка равно `sequence_output`.\n",
    "\n",
    "Для точной настройки мы используем массив `pooled_output`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c256ab6",
   "metadata": {},
   "source": [
    "### Подбор моделей для машинного обучения"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "023a0da3",
   "metadata": {},
   "source": [
    "Мы создадим очень простую точно настроенную модель с моделью предварительной обработки, выбранной **НАИЛУЧШЕЙ моделью**, одним плотным слоем и отсеивающимся слоем.\n",
    "\n",
    "_*Примечание:*_ \n",
    "для получения дополнительной информации о вводе и выводе базовой модели мы можем перейти по URL модели для получения документации. \n",
    "\n",
    "Конкретно здесь нам не нужно беспокоиться об этом, потому что модель предварительной обработки позаботится об этом за нас."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 449,
   "id": "0886629f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_classifier_model():\n",
    "    text_input = tf.keras.layers.Input(shape=(), dtype=tf.string, name='text')\n",
    "    preprocessing_layer = hub.KerasLayer(tfhub_handle_preprocess, name='preprocessing')\n",
    "    encoder_inputs = preprocessing_layer(text_input)\n",
    "    encoder = hub.KerasLayer(tfhub_handle_encoder, trainable=True, name='BERT_encoder')\n",
    "    outputs = encoder(encoder_inputs)\n",
    "    net = outputs['pooled_output']\n",
    "    net = tf.keras.layers.Dropout(0.1)(net)\n",
    "    net = tf.keras.layers.Dense(1, activation=None, name='classifier')(net)\n",
    "    return tf.keras.Model(text_input, net)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e1b29a1",
   "metadata": {},
   "source": [
    "Проверим, что модель запускается с выводом модели предварительной обработки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 450,
   "id": "7b6c0b6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[0.3348399 ]\n",
      " [0.2792921 ]\n",
      " [0.4259739 ]\n",
      " [0.31419381]\n",
      " [0.40028316]\n",
      " [0.2792921 ]\n",
      " [0.32369584]\n",
      " [0.3770468 ]\n",
      " [0.3607976 ]\n",
      " [0.30364728]\n",
      " [0.4259739 ]\n",
      " [0.2792921 ]\n",
      " [0.47554448]\n",
      " [0.3770468 ]\n",
      " [0.5338048 ]\n",
      " [0.3770468 ]\n",
      " [0.30364728]\n",
      " [0.3770468 ]\n",
      " [0.3452456 ]\n",
      " [0.3404307 ]\n",
      " [0.2792921 ]\n",
      " [0.3770468 ]\n",
      " [0.30364728]\n",
      " [0.2792921 ]\n",
      " [0.3770468 ]\n",
      " [0.3404307 ]\n",
      " [0.47301543]\n",
      " [0.43304822]\n",
      " [0.46185058]\n",
      " [0.47554448]\n",
      " [0.40028316]\n",
      " [0.47554448]\n",
      " [0.4089541 ]\n",
      " [0.2792921 ]\n",
      " [0.3603921 ]\n",
      " [0.46185058]\n",
      " [0.4259739 ]\n",
      " [0.2792921 ]\n",
      " [0.3452456 ]\n",
      " [0.3404307 ]\n",
      " [0.43304822]\n",
      " [0.4262962 ]\n",
      " [0.2792921 ]\n",
      " [0.32369584]\n",
      " [0.3452456 ]\n",
      " [0.3607976 ]\n",
      " [0.2792921 ]\n",
      " [0.4262962 ]\n",
      " [0.40028316]\n",
      " [0.28023177]\n",
      " [0.3607976 ]\n",
      " [0.30364728]\n",
      " [0.2792921 ]\n",
      " [0.36923188]\n",
      " [0.31419381]\n",
      " [0.40028316]\n",
      " [0.3404307 ]\n",
      " [0.2792921 ]\n",
      " [0.3770468 ]\n",
      " [0.4259739 ]\n",
      " [0.2792921 ]\n",
      " [0.36923188]\n",
      " [0.28023177]\n",
      " [0.30364728]\n",
      " [0.2792921 ]\n",
      " [0.4259739 ]\n",
      " [0.31419381]\n",
      " [0.40028316]\n",
      " [0.2792921 ]\n",
      " [0.4259739 ]\n",
      " [0.3452456 ]\n",
      " [0.25663224]\n",
      " [0.2792921 ]\n",
      " [0.4259739 ]\n",
      " [0.3770468 ]\n",
      " [0.40028316]\n",
      " [0.3607976 ]\n",
      " [0.2792921 ]\n",
      " [0.3452456 ]\n",
      " [0.32369584]\n",
      " [0.2792921 ]\n",
      " [0.40028316]\n",
      " [0.3404307 ]\n",
      " [0.48894   ]\n",
      " [0.43304822]\n",
      " [0.3770468 ]\n",
      " [0.30364728]\n",
      " [0.31419381]\n",
      " [0.2792921 ]\n",
      " [0.32369584]\n",
      " [0.3452456 ]\n",
      " [0.3452456 ]\n",
      " [0.4259739 ]\n",
      " [0.3603921 ]\n",
      " [0.28023177]\n",
      " [0.43304822]\n",
      " [0.43304822]\n",
      " [0.41638044]\n",
      " [0.2792921 ]\n",
      " [0.4259739 ]\n",
      " [0.31419381]\n",
      " [0.40028316]\n",
      " [0.2792921 ]\n",
      " [0.4259739 ]\n",
      " [0.3452456 ]\n",
      " [0.25663224]\n",
      " [0.2792921 ]\n",
      " [0.4259739 ]\n",
      " [0.3770468 ]\n",
      " [0.40028316]\n",
      " [0.3607976 ]\n",
      " [0.2792921 ]\n",
      " [0.3770468 ]\n",
      " [0.30364728]\n",
      " [0.2792921 ]\n",
      " [0.4259739 ]\n",
      " [0.31419381]\n",
      " [0.40028316]\n",
      " [0.2792921 ]\n",
      " [0.3452456 ]\n",
      " [0.3404307 ]\n",
      " [0.43304822]\n",
      " [0.4262962 ]\n",
      " [0.2792921 ]\n",
      " [0.3607976 ]\n",
      " [0.40028316]\n",
      " [0.43304822]\n",
      " [0.40028316]\n",
      " [0.5338048 ]\n",
      " [0.28023177]\n",
      " [0.3404307 ]\n",
      " [0.4259739 ]\n",
      " [0.2792921 ]\n",
      " [0.43304822]\n",
      " [0.40028316]\n",
      " [0.5338048 ]\n",
      " [0.40028316]\n",
      " [0.43304822]\n",
      " [0.41638044]\n",
      " [0.2792921 ]\n",
      " [0.3770468 ]\n",
      " [0.32369584]\n",
      " [0.2792921 ]\n",
      " [0.4262962 ]\n",
      " [0.3452456 ]\n",
      " [0.46185058]\n",
      " [0.2792921 ]\n",
      " [0.36923188]\n",
      " [0.28023177]\n",
      " [0.3404307 ]\n",
      " [0.4259739 ]\n",
      " [0.2792921 ]\n",
      " [0.4259739 ]\n",
      " [0.3452456 ]\n",
      " [0.2792921 ]\n",
      " [0.3770468 ]\n",
      " [0.3404307 ]\n",
      " [0.47301543]\n",
      " [0.43304822]\n",
      " [0.46185058]\n",
      " [0.47554448]\n",
      " [0.40028316]\n",
      " [0.2792921 ]\n",
      " [0.30364728]\n",
      " [0.40028316]\n",
      " [0.47301543]\n",
      " [0.3452456 ]\n",
      " [0.3404307 ]\n",
      " [0.47554448]\n",
      " [0.2792921 ]\n",
      " [0.47554448]\n",
      " [0.3770468 ]\n",
      " [0.5338048 ]\n",
      " [0.3770468 ]\n",
      " [0.30364728]\n",
      " [0.3770468 ]\n",
      " [0.3452456 ]\n",
      " [0.3404307 ]\n",
      " [0.2792921 ]\n",
      " [0.4259739 ]\n",
      " [0.3770468 ]\n",
      " [0.4259739 ]\n",
      " [0.43304822]\n",
      " [0.40028316]\n",
      " [0.30364728]\n",
      " [0.4089541 ]\n",
      " [0.2792921 ]\n",
      " [0.4262962 ]\n",
      " [0.3452456 ]\n",
      " [0.46185058]\n",
      " [0.33542964]\n",
      " [0.3607976 ]\n",
      " [0.40028316]\n",
      " [0.2792921 ]\n",
      " [0.3607976 ]\n",
      " [0.40028316]\n",
      " [0.28023177]\n",
      " [0.43304822]\n",
      " [0.43304822]\n",
      " [0.4262962 ]\n",
      " [0.2792921 ]\n",
      " [0.3452456 ]\n",
      " [0.3404307 ]\n",
      " [0.43304822]\n",
      " [0.4262962 ]\n",
      " [0.2792921 ]\n",
      " [0.28023177]\n",
      " [0.47301543]\n",
      " [0.4431472 ]\n",
      " [0.3404307 ]\n",
      " [0.3452456 ]\n",
      " [0.36923188]\n",
      " [0.43304822]\n",
      " [0.40028316]\n",
      " [0.47554448]\n",
      " [0.48894   ]\n",
      " [0.3770468 ]\n",
      " [0.3404307 ]\n",
      " [0.48894   ]\n",
      " [0.2792921 ]\n",
      " [0.4259739 ]\n",
      " [0.31419381]\n",
      " [0.28023177]\n",
      " [0.4259739 ]\n",
      " [0.2792921 ]\n",
      " [0.3452456 ]\n",
      " [0.3404307 ]\n",
      " [0.40028316]\n",
      " [0.2792921 ]\n",
      " [0.47301543]\n",
      " [0.43304822]\n",
      " [0.46185058]\n",
      " [0.3603921 ]\n",
      " [0.2792921 ]\n",
      " [0.36923188]\n",
      " [0.28023177]\n",
      " [0.30364728]\n",
      " [0.2792921 ]\n",
      " [0.3770468 ]\n",
      " [0.3404307 ]\n",
      " [0.2792921 ]\n",
      " [0.4259739 ]\n",
      " [0.31419381]\n",
      " [0.40028316]\n",
      " [0.2792921 ]\n",
      " [0.30364728]\n",
      " [0.40028316]\n",
      " [0.47301543]\n",
      " [0.3452456 ]\n",
      " [0.3404307 ]\n",
      " [0.47554448]\n",
      " [0.2792921 ]\n",
      " [0.47554448]\n",
      " [0.3770468 ]\n",
      " [0.5338048 ]\n",
      " [0.3770468 ]\n",
      " [0.30364728]\n",
      " [0.3770468 ]\n",
      " [0.3452456 ]\n",
      " [0.3404307 ]\n",
      " [0.2792921 ]\n",
      " [0.43304822]\n",
      " [0.3452456 ]\n",
      " [0.3404307 ]\n",
      " [0.48894   ]\n",
      " [0.40028316]\n",
      " [0.3607976 ]\n",
      " [0.2792921 ]\n",
      " [0.4259739 ]\n",
      " [0.31419381]\n",
      " [0.28023177]\n",
      " [0.3404307 ]\n",
      " [0.2792921 ]\n",
      " [0.4259739 ]\n",
      " [0.31419381]\n",
      " [0.40028316]\n",
      " [0.2792921 ]\n",
      " [0.3452456 ]\n",
      " [0.4259739 ]\n",
      " [0.31419381]\n",
      " [0.40028316]\n",
      " [0.3607976 ]\n",
      " [0.4089541 ]\n",
      " [0.2792921 ]\n",
      " [0.28023177]\n",
      " [0.3404307 ]\n",
      " [0.47554448]\n",
      " [0.2792921 ]\n",
      " [0.4259739 ]\n",
      " [0.31419381]\n",
      " [0.28023177]\n",
      " [0.4259739 ]\n",
      " [0.33542964]\n",
      " [0.30364728]\n",
      " [0.2792921 ]\n",
      " [0.3404307 ]\n",
      " [0.3452456 ]\n",
      " [0.4259739 ]\n",
      " [0.2792921 ]\n",
      " [0.28023177]\n",
      " [0.3404307 ]\n",
      " [0.4262962 ]\n",
      " [0.4259739 ]\n",
      " [0.31419381]\n",
      " [0.3770468 ]\n",
      " [0.3404307 ]\n",
      " [0.48894   ]\n",
      " [0.2792921 ]\n",
      " [0.36923188]\n",
      " [0.3452456 ]\n",
      " [0.3607976 ]\n",
      " [0.4259739 ]\n",
      " [0.31419381]\n",
      " [0.2792921 ]\n",
      " [0.30364728]\n",
      " [0.31419381]\n",
      " [0.3452456 ]\n",
      " [0.46185058]\n",
      " [0.4259739 ]\n",
      " [0.3770468 ]\n",
      " [0.3404307 ]\n",
      " [0.48894   ]\n",
      " [0.2792921 ]\n",
      " [0.28023177]\n",
      " [0.3603921 ]\n",
      " [0.3452456 ]\n",
      " [0.46185058]\n",
      " [0.4259739 ]\n",
      " [0.41638044]\n",
      " [0.2792921 ]\n",
      " [0.28023177]\n",
      " [0.3404307 ]\n",
      " [0.47554448]\n",
      " [0.2792921 ]\n",
      " [0.36923188]\n",
      " [0.3452456 ]\n",
      " [0.46185058]\n",
      " [0.43304822]\n",
      " [0.47554448]\n",
      " [0.2792921 ]\n",
      " [0.4262962 ]\n",
      " [0.3452456 ]\n",
      " [0.46185058]\n",
      " [0.2792921 ]\n",
      " [0.25663224]\n",
      " [0.43304822]\n",
      " [0.40028316]\n",
      " [0.28023177]\n",
      " [0.30364728]\n",
      " [0.40028316]\n",
      " [0.2792921 ]\n",
      " [0.30364728]\n",
      " [0.4259739 ]\n",
      " [0.3452456 ]\n",
      " [0.25663224]\n",
      " [0.2792921 ]\n",
      " [0.4259739 ]\n",
      " [0.28023177]\n",
      " [0.43304822]\n",
      " [0.4431472 ]\n",
      " [0.3770468 ]\n",
      " [0.3404307 ]\n",
      " [0.48894   ]\n",
      " [0.2792921 ]\n",
      " [0.28023177]\n",
      " [0.3603921 ]\n",
      " [0.3452456 ]\n",
      " [0.46185058]\n",
      " [0.4259739 ]\n",
      " [0.2792921 ]\n",
      " [0.3348399 ]\n",
      " [0.3348399 ]\n",
      " [0.36814624]\n",
      " [0.28023177]\n",
      " [0.507626  ]\n",
      " [0.3452456 ]\n",
      " [0.3607976 ]\n",
      " [0.3348399 ]\n",
      " [0.3348399 ]\n",
      " [0.2792921 ]\n",
      " [0.4259739 ]\n",
      " [0.3607976 ]\n",
      " [0.3452456 ]\n",
      " [0.25663224]\n",
      " [0.31419381]\n",
      " [0.3770468 ]\n",
      " [0.40028316]\n",
      " [0.30364728]\n",
      " [0.41638044]\n",
      " [0.2792921 ]\n",
      " [0.4259739 ]\n",
      " [0.31419381]\n",
      " [0.40028316]\n",
      " [0.4262962 ]\n",
      " [0.33542964]\n",
      " [0.3607976 ]\n",
      " [0.40028316]\n",
      " [0.2792921 ]\n",
      " [0.507626  ]\n",
      " [0.46185058]\n",
      " [0.30364728]\n",
      " [0.4259739 ]\n",
      " [0.2792921 ]\n",
      " [0.4259739 ]\n",
      " [0.3607976 ]\n",
      " [0.3452456 ]\n",
      " [0.25663224]\n",
      " [0.31419381]\n",
      " [0.3770468 ]\n",
      " [0.40028316]\n",
      " [0.30364728]\n",
      " [0.4089541 ]\n",
      " [0.2792921 ]\n",
      " [0.4259739 ]\n",
      " [0.31419381]\n",
      " [0.40028316]\n",
      " [0.3607976 ]\n",
      " [0.40028316]\n",
      " [0.33542964]\n",
      " [0.30364728]\n",
      " [0.2792921 ]\n",
      " [0.3404307 ]\n",
      " [0.3452456 ]\n",
      " [0.4259739 ]\n",
      " [0.31419381]\n",
      " [0.3770468 ]\n",
      " [0.3404307 ]\n",
      " [0.48894   ]\n",
      " [0.2792921 ]\n",
      " [0.36814624]\n",
      " [0.28023177]\n",
      " [0.507626  ]\n",
      " [0.3452456 ]\n",
      " [0.3607976 ]\n",
      " [0.2792921 ]\n",
      " [0.3452456 ]\n",
      " [0.3607976 ]\n",
      " [0.2792921 ]\n",
      " [0.36814624]\n",
      " [0.3770468 ]\n",
      " [0.3404307 ]\n",
      " [0.3452456 ]\n",
      " [0.3607976 ]\n",
      " [0.2792921 ]\n",
      " [0.28023177]\n",
      " [0.3603921 ]\n",
      " [0.3452456 ]\n",
      " [0.46185058]\n",
      " [0.4259739 ]\n",
      " [0.2792921 ]\n",
      " [0.4259739 ]\n",
      " [0.31419381]\n",
      " [0.40028316]\n",
      " [0.36814624]\n",
      " [0.41638044]\n",
      " [0.2792921 ]\n",
      " [0.29149228]\n",
      " [0.2792921 ]\n",
      " [0.507626  ]\n",
      " [0.28023177]\n",
      " [0.4262962 ]\n",
      " [0.2792921 ]\n",
      " [0.33483988]], shape=(463, 1), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "classifier_model = build_classifier_model()\n",
    "bert_raw_result = classifier_model(tf.constant(text_test))\n",
    "print(tf.sigmoid(bert_raw_result))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8af961ce",
   "metadata": {},
   "source": [
    "Выходные данные бессмысленны, потому что модель еще не была обучена"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b5e82c9",
   "metadata": {},
   "source": [
    "## Машинное обучение"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80e05c70",
   "metadata": {},
   "source": [
    "Теперь у нас есть все компоненты для обучения модели, включая модуль предварительной обработки, кодировщик BERT, данные и классификатор"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eff3e105",
   "metadata": {},
   "source": [
    "### Функция потерь\n",
    "\n",
    "Поскольку это задача двоичной классификации, и модель выдает вероятность (единичный уровень), вы будете использовать функцию потерь `losses.BinaryCrossentropy`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 451,
   "id": "acafdc82",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = tf.keras.losses.BinaryCrossentropy(from_logits=True)\n",
    "metrics = tf.metrics.BinaryAccuracy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c22e0779",
   "metadata": {},
   "source": [
    "### Оптимизация\n",
    "\n",
    "Для точной настройки воспользуемся тем же оптимизатором, с которым изначально обучался БЕРТ: \"Адаптивные моменты\" (Adam). Этот оптимизатор минимизирует потери при прогнозировании и выполняет регуляризацию путем уменьшения веса (без использования моментов), которая также известна как [AdamW](https://arxiv.org/abs/1711.05101 ).\n",
    "\n",
    "Для скорости обучения (`init_lr`) будем использовать тот же график, что и для предварительной тренировки BERT: линейное уменьшение условной начальной скорости обучения с префиксом линейной фазы разминки в течение первых 10% шагов обучения (`num_warmup_steps`). В соответствии с ЛУЧШЕЙ статьей, начальная скорость обучения меньше для точной настройки (лучше всего 5e-5, 3e-5, 2e-5)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 452,
   "id": "04de29e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 2\n",
    "steps_per_epoch = tf.data.experimental.cardinality(toxic_comments_csv_ds_train).numpy()\n",
    "num_train_steps = steps_per_epoch * epochs\n",
    "num_warmup_steps = int(0.1*num_train_steps)\n",
    "\n",
    "init_lr = 3e-5\n",
    "optimizer = optimization.create_optimizer(init_lr=init_lr, num_train_steps=num_train_steps, num_warmup_steps=num_warmup_steps, optimizer_type='adamw')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a3eea49",
   "metadata": {},
   "source": [
    "### Загружаем модель BERT и обучаем ее"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85f2b5f6",
   "metadata": {},
   "source": [
    "Используя `classifier_model`, который мы создали ранее, мы можете скомпилировать модель с потерями, метрикой и оптимизатором."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 453,
   "id": "e6e10bc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier_model.compile(optimizer=optimizer, loss=loss, metrics=metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb3f9f03",
   "metadata": {},
   "source": [
    "Примечание: время обучения будет варьироваться в зависимости от сложности выбранной вами модели BERT."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 454,
   "id": "7977930c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model with https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-4_H-512_A-8/1\n",
      "Epoch 1/2\n",
      "    883/Unknown - 2586s 3s/step - loss: -1653.4751 - binary_accuracy: 0.0000e+00"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[454], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTraining model with \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtfhub_handle_encoder\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m----> 3\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mclassifier_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoxic_comments_csv_ds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mval_ds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mepochs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mD:\\Program File\\Anaconda\\envs\\practicum\\lib\\site-packages\\keras\\utils\\traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mD:\\Program File\\Anaconda\\envs\\practicum\\lib\\site-packages\\keras\\engine\\training.py:1564\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1556\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[0;32m   1557\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   1558\u001b[0m     epoch_num\u001b[38;5;241m=\u001b[39mepoch,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1561\u001b[0m     _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[0;32m   1562\u001b[0m ):\n\u001b[0;32m   1563\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[1;32m-> 1564\u001b[0m     tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1565\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[0;32m   1566\u001b[0m         context\u001b[38;5;241m.\u001b[39masync_wait()\n",
      "File \u001b[1;32mD:\\Program File\\Anaconda\\envs\\practicum\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mD:\\Program File\\Anaconda\\envs\\practicum\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:915\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    912\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    914\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 915\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    917\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    918\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32mD:\\Program File\\Anaconda\\envs\\practicum\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:947\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    944\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[0;32m    945\u001b[0m   \u001b[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[0;32m    946\u001b[0m   \u001b[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[1;32m--> 947\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stateless_fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)  \u001b[38;5;66;03m# pylint: disable=not-callable\u001b[39;00m\n\u001b[0;32m    948\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stateful_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    949\u001b[0m   \u001b[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[0;32m    950\u001b[0m   \u001b[38;5;66;03m# in parallel.\u001b[39;00m\n\u001b[0;32m    951\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n",
      "File \u001b[1;32mD:\\Program File\\Anaconda\\envs\\practicum\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:2496\u001b[0m, in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2478\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   2479\u001b[0m              fullargspec,\n\u001b[0;32m   2480\u001b[0m              is_method,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   2484\u001b[0m              name\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   2485\u001b[0m              jit_compile\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m   2486\u001b[0m   \u001b[38;5;124;03m\"\"\"Constructs a FunctionSpec describing a python function.\u001b[39;00m\n\u001b[0;32m   2487\u001b[0m \n\u001b[0;32m   2488\u001b[0m \u001b[38;5;124;03m  Args:\u001b[39;00m\n\u001b[0;32m   2489\u001b[0m \u001b[38;5;124;03m    fullargspec: `tf_inspect.FullArgSpec` object describing the function.\u001b[39;00m\n\u001b[0;32m   2490\u001b[0m \u001b[38;5;124;03m    is_method: True if the function is a method.\u001b[39;00m\n\u001b[0;32m   2491\u001b[0m \u001b[38;5;124;03m    input_signature: a signature of the function (None, if variable)\u001b[39;00m\n\u001b[0;32m   2492\u001b[0m \u001b[38;5;124;03m    is_pure: if True all input arguments (including variables and constants)\u001b[39;00m\n\u001b[0;32m   2493\u001b[0m \u001b[38;5;124;03m      will be converted to tensors and no variable changes allowed.\u001b[39;00m\n\u001b[0;32m   2494\u001b[0m \u001b[38;5;124;03m    experimental_follow_type_hints: see `tf.function`.\u001b[39;00m\n\u001b[0;32m   2495\u001b[0m \u001b[38;5;124;03m    name: Name of the function\u001b[39;00m\n\u001b[1;32m-> 2496\u001b[0m \u001b[38;5;124;03m    jit_compile: see `tf.function`.\u001b[39;00m\n\u001b[0;32m   2497\u001b[0m \u001b[38;5;124;03m  \"\"\"\u001b[39;00m\n\u001b[0;32m   2498\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fullargspec \u001b[38;5;241m=\u001b[39m fullargspec\n\u001b[0;32m   2499\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_is_method \u001b[38;5;241m=\u001b[39m is_method\n",
      "File \u001b[1;32mD:\\Program File\\Anaconda\\envs\\practicum\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:1862\u001b[0m, in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1859\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n\u001b[0;32m   1860\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m executing_eagerly:\n\u001b[0;32m   1861\u001b[0m   flat_outputs \u001b[38;5;241m=\u001b[39m forward_function\u001b[38;5;241m.\u001b[39mcall(\n\u001b[1;32m-> 1862\u001b[0m       ctx, args_with_tangents, cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_manager)\n\u001b[0;32m   1863\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1864\u001b[0m   \u001b[38;5;28;01mwith\u001b[39;00m default_graph\u001b[38;5;241m.\u001b[39m_override_gradient_function(  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[0;32m   1865\u001b[0m       {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPartitionedCall\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_gradient_function(),\n\u001b[0;32m   1866\u001b[0m        \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mStatefulPartitionedCall\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_gradient_function()}):\n",
      "File \u001b[1;32mD:\\Program File\\Anaconda\\envs\\practicum\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:499\u001b[0m, in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    497\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _InterpolateFunctionError(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    498\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m cancellation_manager \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 499\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute(\n\u001b[0;32m    500\u001b[0m         \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msignature\u001b[38;5;241m.\u001b[39mname),\n\u001b[0;32m    501\u001b[0m         num_outputs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_outputs,\n\u001b[0;32m    502\u001b[0m         inputs\u001b[38;5;241m=\u001b[39margs,\n\u001b[0;32m    503\u001b[0m         attrs\u001b[38;5;241m=\u001b[39mattrs,\n\u001b[0;32m    504\u001b[0m         ctx\u001b[38;5;241m=\u001b[39mctx)\n\u001b[0;32m    505\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    506\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m    507\u001b[0m         \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msignature\u001b[38;5;241m.\u001b[39mname),\n\u001b[0;32m    508\u001b[0m         num_outputs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    511\u001b[0m         ctx\u001b[38;5;241m=\u001b[39mctx,\n\u001b[0;32m    512\u001b[0m         cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_manager)\n",
      "File \u001b[1;32mD:\\Program File\\Anaconda\\envs\\practicum\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:54\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 54\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     55\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     56\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     57\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "print(f'Training model with {tfhub_handle_encoder}')\n",
    "\n",
    "history = classifier_model.fit(x=toxic_comments_csv_ds, validation_data=val_ds, epochs=epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a43be519",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "\n",
    "Комментарий студента V1: У меня вопрос к ревью. Я сделал примерно то, что было по образцу с вебинара. Но здесь не указан конец шага, т.е. там вместо числа стоит `Unknown`. Получается, что здесь будет бесконечная итерация\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0eef49b",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "\n",
    "<b>Совет: </b> https://datascience.stackexchange.com/questions/74168/epoch-1-5-wont-stop\n",
    "</div>\n",
    "\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "\n",
    "<b>Совет: </b> Вообще говоря, лучше использовать torch. Он намного более популярен сейчас. Вот специализированный БЕРТ для него: https://huggingface.co/unitary/toxic-bert\n",
    "</div>"
   ]
  },
  {
   "attachments": {
    "image.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "id": "1bc9e5c0",
   "metadata": {},
   "source": [
    "![image.png](attachment:image.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cbb3dc4",
   "metadata": {},
   "source": [
    "### Оценка моделей"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 455,
   "id": "b44c06fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     54/Unknown - 40s 716ms/step - loss: -5944.1006 - binary_accuracy: 0.0000e+00"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[455], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m loss, accuracy \u001b[38;5;241m=\u001b[39m \u001b[43mclassifier_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtoxic_comments_csv_ds_test\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLoss: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mloss\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAccuracy: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00maccuracy\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32mD:\\Program File\\Anaconda\\envs\\practicum\\lib\\site-packages\\keras\\utils\\traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mD:\\Program File\\Anaconda\\envs\\practicum\\lib\\site-packages\\keras\\engine\\training.py:1947\u001b[0m, in \u001b[0;36mModel.evaluate\u001b[1;34m(self, x, y, batch_size, verbose, sample_weight, steps, callbacks, max_queue_size, workers, use_multiprocessing, return_dict, **kwargs)\u001b[0m\n\u001b[0;32m   1943\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[0;32m   1944\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest\u001b[39m\u001b[38;5;124m\"\u001b[39m, step_num\u001b[38;5;241m=\u001b[39mstep, _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m\n\u001b[0;32m   1945\u001b[0m ):\n\u001b[0;32m   1946\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_test_batch_begin(step)\n\u001b[1;32m-> 1947\u001b[0m     tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtest_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1948\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[0;32m   1949\u001b[0m         context\u001b[38;5;241m.\u001b[39masync_wait()\n",
      "File \u001b[1;32mD:\\Program File\\Anaconda\\envs\\practicum\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mD:\\Program File\\Anaconda\\envs\\practicum\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:915\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    912\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    914\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 915\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    917\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    918\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32mD:\\Program File\\Anaconda\\envs\\practicum\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:954\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    951\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[0;32m    952\u001b[0m \u001b[38;5;66;03m# In this case we have not created variables on the first call. So we can\u001b[39;00m\n\u001b[0;32m    953\u001b[0m \u001b[38;5;66;03m# run the first trace but we should fail if variables are created.\u001b[39;00m\n\u001b[1;32m--> 954\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stateful_fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    955\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_created_variables \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m ALLOW_DYNAMIC_VARIABLE_CREATION:\n\u001b[0;32m    956\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCreating variables on a non-first call to a function\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    957\u001b[0m                    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m decorated with tf.function.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mD:\\Program File\\Anaconda\\envs\\practicum\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:2496\u001b[0m, in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2478\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   2479\u001b[0m              fullargspec,\n\u001b[0;32m   2480\u001b[0m              is_method,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   2484\u001b[0m              name\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   2485\u001b[0m              jit_compile\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m   2486\u001b[0m   \u001b[38;5;124;03m\"\"\"Constructs a FunctionSpec describing a python function.\u001b[39;00m\n\u001b[0;32m   2487\u001b[0m \n\u001b[0;32m   2488\u001b[0m \u001b[38;5;124;03m  Args:\u001b[39;00m\n\u001b[0;32m   2489\u001b[0m \u001b[38;5;124;03m    fullargspec: `tf_inspect.FullArgSpec` object describing the function.\u001b[39;00m\n\u001b[0;32m   2490\u001b[0m \u001b[38;5;124;03m    is_method: True if the function is a method.\u001b[39;00m\n\u001b[0;32m   2491\u001b[0m \u001b[38;5;124;03m    input_signature: a signature of the function (None, if variable)\u001b[39;00m\n\u001b[0;32m   2492\u001b[0m \u001b[38;5;124;03m    is_pure: if True all input arguments (including variables and constants)\u001b[39;00m\n\u001b[0;32m   2493\u001b[0m \u001b[38;5;124;03m      will be converted to tensors and no variable changes allowed.\u001b[39;00m\n\u001b[0;32m   2494\u001b[0m \u001b[38;5;124;03m    experimental_follow_type_hints: see `tf.function`.\u001b[39;00m\n\u001b[0;32m   2495\u001b[0m \u001b[38;5;124;03m    name: Name of the function\u001b[39;00m\n\u001b[1;32m-> 2496\u001b[0m \u001b[38;5;124;03m    jit_compile: see `tf.function`.\u001b[39;00m\n\u001b[0;32m   2497\u001b[0m \u001b[38;5;124;03m  \"\"\"\u001b[39;00m\n\u001b[0;32m   2498\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fullargspec \u001b[38;5;241m=\u001b[39m fullargspec\n\u001b[0;32m   2499\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_is_method \u001b[38;5;241m=\u001b[39m is_method\n",
      "File \u001b[1;32mD:\\Program File\\Anaconda\\envs\\practicum\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:1862\u001b[0m, in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1859\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n\u001b[0;32m   1860\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m executing_eagerly:\n\u001b[0;32m   1861\u001b[0m   flat_outputs \u001b[38;5;241m=\u001b[39m forward_function\u001b[38;5;241m.\u001b[39mcall(\n\u001b[1;32m-> 1862\u001b[0m       ctx, args_with_tangents, cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_manager)\n\u001b[0;32m   1863\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1864\u001b[0m   \u001b[38;5;28;01mwith\u001b[39;00m default_graph\u001b[38;5;241m.\u001b[39m_override_gradient_function(  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[0;32m   1865\u001b[0m       {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPartitionedCall\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_gradient_function(),\n\u001b[0;32m   1866\u001b[0m        \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mStatefulPartitionedCall\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_gradient_function()}):\n",
      "File \u001b[1;32mD:\\Program File\\Anaconda\\envs\\practicum\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:499\u001b[0m, in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    497\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _InterpolateFunctionError(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    498\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m cancellation_manager \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 499\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute(\n\u001b[0;32m    500\u001b[0m         \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msignature\u001b[38;5;241m.\u001b[39mname),\n\u001b[0;32m    501\u001b[0m         num_outputs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_outputs,\n\u001b[0;32m    502\u001b[0m         inputs\u001b[38;5;241m=\u001b[39margs,\n\u001b[0;32m    503\u001b[0m         attrs\u001b[38;5;241m=\u001b[39mattrs,\n\u001b[0;32m    504\u001b[0m         ctx\u001b[38;5;241m=\u001b[39mctx)\n\u001b[0;32m    505\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    506\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m    507\u001b[0m         \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msignature\u001b[38;5;241m.\u001b[39mname),\n\u001b[0;32m    508\u001b[0m         num_outputs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    511\u001b[0m         ctx\u001b[38;5;241m=\u001b[39mctx,\n\u001b[0;32m    512\u001b[0m         cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_manager)\n",
      "File \u001b[1;32mD:\\Program File\\Anaconda\\envs\\practicum\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:54\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 54\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     55\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     56\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     57\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "loss, accuracy = classifier_model.evaluate(toxic_comments_csv_ds_test)\n",
    "\n",
    "print(f'Loss: {loss}')\n",
    "print(f'Accuracy: {accuracy}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fd41e66",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "\n",
    "Комментарий студента V1: И здесь аналогично\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "attachments": {
    "image.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "id": "3e798a2d",
   "metadata": {},
   "source": [
    "![image.png](attachment:image.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73dae050",
   "metadata": {},
   "source": [
    "### Построим график точности и потери с течением времени\n",
    "\n",
    "На основе объекта `History`, возвращаемого `model.fit()`. Вы можете построить график потерь при обучении и валидации для сравнения, а также точности обучения и валидации:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 456,
   "id": "af81b6f5",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'history' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[456], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m history_dict \u001b[38;5;241m=\u001b[39m \u001b[43mhistory\u001b[49m\u001b[38;5;241m.\u001b[39mhistory\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(history_dict\u001b[38;5;241m.\u001b[39mkeys())\n\u001b[0;32m      4\u001b[0m acc \u001b[38;5;241m=\u001b[39m history_dict[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbinary_accuracy\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "\u001b[1;31mNameError\u001b[0m: name 'history' is not defined"
     ]
    }
   ],
   "source": [
    "history_dict = history.history\n",
    "print(history_dict.keys())\n",
    "\n",
    "acc = history_dict['binary_accuracy']\n",
    "val_acc = history_dict['val_binary_accuracy']\n",
    "loss = history_dict['loss']\n",
    "val_loss = history_dict['val_loss']\n",
    "\n",
    "epochs = range(1, len(acc) + 1)\n",
    "fig = plt.figure(figsize=(10, 6))\n",
    "fig.tight_layout()\n",
    "\n",
    "plt.subplot(2, 1, 1)\n",
    "# r is for \"solid red line\"\n",
    "plt.plot(epochs, loss, 'r', label='Training loss')\n",
    "# b is for \"solid blue line\"\n",
    "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "# plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(2, 1, 2)\n",
    "plt.plot(epochs, acc, 'r', label='Training acc')\n",
    "plt.plot(epochs, val_acc, 'b', label='Validation acc')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend(loc='lower right')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db6c2890",
   "metadata": {},
   "source": [
    "## Проверим на F1-метрику"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 504,
   "id": "5b7aefbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Каким образом можно вытянуть предсказания, если там выдает только функцию потери?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 505,
   "id": "045b6575",
   "metadata": {},
   "outputs": [],
   "source": [
    "# В процессе"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47c05298",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a1b6f49",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
