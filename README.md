# Проектная работа: Обучение модели классификации комментариев

## Описание проекта
Интернет-магазин «Викишоп» запускает новый сервис. Теперь пользователи могут редактировать и дополнять описания товаров, как в вики-сообществах. То есть клиенты предлагают свои правки и комментируют изменения других. Магазину нужен инструмент, который будет искать токсичные комментарии и отправлять их на модерацию. 

Нам необходимо построить обученную модель, которая классифицирует комментарии на позитивные и негативные. В вашем распоряжении набор данных с разметкой о токсичности правок.

Также модель должна соблюсти со значением метрики качества **F1 не меньше 0.75**. 

## План по выполнению проекта

Способы обучения данного проекта будут делиться на 2 части: 
- Библиотечными способами - **scikit-learn** 
- Нейронными способами - **BERT**

## Описание данных

Данные лежат в файле `/datasets/toxic_comments.csv`

Столбец `text` в нём содержит текст комментария, а `toxic` — целевой признак.

# Исследовательская работа

## Анализ

Мы получили датасет с общей сложности около 160 000 текстов. Рассмотрели баланс классов позитивных и токсичных комментарий.

![img.png](image/img.png)

Как и видим, что много токсичных комментариев нежели позитивных.

## Предобработка данных и подготовка к обучению

Установили СТОП-СЛОВО и другие словари, а также лемматизировали текстов. 
Разделили обучающую и тестовую выборку со соотношением 75% и 25%.


## Машинное обучение

###### Список семейств моделей, применяемых на обучение
- LogisticRegression
- RandomForestClassifier
- DecisionTreeClassifier
- CatBoostClassifier

###### Результаты F1-SCORE

![img_1.png](image/img_1.png)

Но нам интересует **F1** не менее **0.75**, тогда

![img_2.png](image/img_2.png)

Результат оказался оптимальным, т.е. F1 = 0,779

Лучшей моделей оказалсь `LogisticRegression`, проверим на тестовой выборке

Установка лучшей модели через `Pipeline`

![img_3.png](image/img_3.png)

После обучения предсказание и F1-SCORE получились нормальными

```text
F1 VALID: 0.779
Предсказание: 0.087
CPU times: user 1.33 s, sys: 0 ns, total: 1.33 s
Wall time: 1.33 s
```

###### График распределения плотности предсказанных и истинных значений

![img_4.png](image/img_4.png)

# Вывод
Самой лучшей моделей является LogisticRegression - F1 на тестовой выборки составляет `0.779`, а скорость обучения составляет аж **8 секунды**, время предсказания - **0,087 секунда**. 

Вполне очень акдеватный результат, чтобы выбрать эту модель для реализации. 

Есть другая модель, но, к сожалению, не попал в топ, т.к. метрика F1 ниже заявленного - `0,75`.

---

---

---

# Исследовательская работа с применением технологии BERT

###### Предобработку данных мы уже совершили

## Установка настройки конфигурации для обучения
```python
MAX_LEN = 200
TRAIN_BATCH_SIZE = 8
VALID_BATCH_SIZE = 4
EPOCHS = 2
LEARNING_RATE = 1e-05
tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')
```

## Создание нейронной сети для тонкой настройки

### Нейронная сеть
- Мы будем создавать нейронную сеть с `BERTClass`.
- У этой сети будет `Bert` модель. Далее следуют `Droput` и `Linear Layer`. Они добавлены с целью **Упорядочивания** и **Regulariaztion** соответственно.
- В прямом цикле есть 2 выходных данных из слоя `Bert Model`.
- Второй вывод `output_1` или называемый `объединенным выводом` передается в `Drop Out layer`, а последующий вывод передается в `Linear layer`.
- Обратите внимание, что количество измерений для "линейного слоя" равно **6** потому что это общее количество категорий, по которым мы хотим классифицировать нашу модель.
- Данные будут переданы в `BertClass`, как определено в наборе данных.
- Выходные данные конечного уровня - это то, что будет использоваться для расчета потерь и определения точности прогнозирования моделей.
- Мы инициируем экземпляр сети под названием `model`. Этот экземпляр будет использоваться для обучения, а затем для сохранения окончательной обученной модели для последующего вывода.
 
### Функция потерь и оптимизатор
- Потеря определяется в следующей ячейке как `loss_fn`.
- Как определено выше, используемая функция потерь будет представлять собой комбинацию двоичной перекрестной энтропии, которая реализована как [BCELogits Loss](https://pytorch.org/docs/stable/nn.html#bcewithlogitsloss ) в PyTorch
- `Optimizer` определен в следующей ячейке.
- `Optimizer` используется для обновления весов нейронной сети для повышения ее производительности.


## Точная настройка модели

### Точная настройка модели

После всех усилий по загрузке и подготовке данных и наборов данных, созданию модели и определению ее потерь и оптимизатора. Вероятно, это самый простой шаг в процессе.

Здесь мы определяем обучающую функцию, которая обучает модель на основе обучающего набора данных, созданного выше, заданное количество раз (ЭПОХА), эпоха определяет, сколько раз полные данные будут передаваться по сети.

Для точной настройки нейронной сети в этой функции происходят следующие события:
- Загрузчик данных передает данные в модель в зависимости от размера пакета.
- Последующие выходные данные модели и фактическая категория сравниваются для расчета потерь.
- Значение потерь используется для оптимизации весов нейронов в сети.
- После каждых 5000 шагов в консоли выводится значение потерь.

Как мы можем увидеть, всего за 1 эпоху на последнем шаге модель работала с незначительными потерями в 0,022, т.е. выходной сигнал сети чрезвычайно близок к фактическому выходному сигналу.

```python
def train(epoch):
    model.train()
    for _,data in enumerate(training_loader, 0):
        ids = data['ids'].to(device, dtype = torch.long)
        mask = data['mask'].to(device, dtype = torch.long)
        token_type_ids = data['token_type_ids'].to(device, dtype = torch.long)
        targets = data['targets'].to(device, dtype = torch.float)

        outputs = model(ids, mask, token_type_ids)
        
        optimizer.zero_grad()
        loss = loss_fn(outputs, targets)
        if _%5000==0:
            print(f'Epoch: {epoch}, Loss:  {loss.item()}')
        
        optimizer.zero_grad()
        loss.backward()
        optimizer.step()

for epoch in range(EPOCHS):
    train(epoch)
```

```text
output:

Epoch: 0, Loss:  0.733110785484314
Epoch: 0, Loss:  0.39082932472229004
Epoch: 0, Loss:  0.005783333443105221
Epoch: 0, Loss:  0.09499093890190125
Epoch: 1, Loss:  0.01712093874812126
Epoch: 1, Loss:  0.00039071450009942055
Epoch: 1, Loss:  0.322614461183548
Epoch: 1, Loss:  0.02024523913860321

CPU times: user 1h 41min 16s, sys: 53min 13s, total: 2h 34min 29s
Wall time: 2h 35min 39s
```

## Проверим на F1-метрику

На этапе проверки мы передаем невидимые данные (тестовый набор данных) в модель. Этот шаг определяет, насколько хорошо модель работает с невидимыми данными.

Эти невидимые данные составляют 20% от `train.csv`, которые были отделены на этапе создания набора данных.
На этапе проверки веса модели не обновляются. Только конечный результат сравнивается с фактическим значением. Это сравнение затем используется для расчета точности модели.

Как определено выше, чтобы получить оценку производительности наших моделей, мы используем следующие показатели.
- Accuracy Score
- F1-score
- F1-score MACRO
- F1-score MICRO

Мы получаем потрясающие результаты по всем этим 3 категориям, просто обучая модель в течение 1 эпохи.

```python
def validation(epoch):
    model.eval()
    fin_targets=[]
    fin_outputs=[]
    with torch.no_grad():
        for _, data in enumerate(testing_loader, 0):
            ids = data['ids'].to(device, dtype = torch.long)
            mask = data['mask'].to(device, dtype = torch.long)
            token_type_ids = data['token_type_ids'].to(device, dtype = torch.long)
            targets = data['targets'].to(device, dtype = torch.float)
            outputs = model(ids, mask, token_type_ids)
            fin_targets.extend(targets.cpu().detach().numpy().tolist())
            fin_outputs.extend(torch.sigmoid(outputs).cpu().detach().numpy().tolist())
    return fin_outputs, fin_targets

for epoch in range(EPOCHS):
    outputs, targets = validation(epoch)
    outputs = np.array(outputs) >= 0.5
    accuracy = metrics.accuracy_score(targets, outputs)
    f1_score = metrics.f1_score(targets, outputs)
    f1_score_micro = metrics.f1_score(targets, outputs, average='micro')
    f1_score_macro = metrics.f1_score(targets, outputs, average='macro')
    print(f"Accuracy Score = {accuracy}")
    print(f"F1 Score = {f1_score}")
    print(f"F1 Score (Micro) = {f1_score_micro}")
    print(f"F1 Score (Macro) = {f1_score_macro}")
```

```text
output:

Accuracy Score = 0.9693954422750958
F1 Score = 0.8411275867687795
F1 Score (Micro) = 0.9693954422750958
F1 Score (Macro) = 0.9120971649260977

Accuracy Score = 0.9693954422750958
F1 Score = 0.8411275867687795
F1 Score (Micro) = 0.9693954422750958
F1 Score (Macro) = 0.9120971649260977

CPU times: user 14min 20s, sys: 1.26 s, total: 14min 21s
Wall time: 14min 24s
```


# Вывод

F1-SCORE у модели BERT с помощью библиотеки PyTorch получилось очень неплохой, аж **0,841** значений. Однако у этой модели есть основные недостатки, от которых мы избегаем: время обучения и предсказаня. Время обучения занимает аж **1,5 часа** в среднем. А время предсказания меньше **1\4 часа**.

Если нам поставлена задача создать модель, которая дает высокие результаты, тогда нам следует применять глубокие обучения, в противном случае можно применять легкие модели и быстро получить результаты для предварительного прогнозирования.
