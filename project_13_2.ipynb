{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "24690939",
   "metadata": {},
   "source": [
    "# Алгоритм Adam\n",
    "\n",
    "Обучим сеть LeNet на графических картах GPU. Но прежде рассмотрим ещё один алгоритм оптимизации, который поможет улучшить результаты.\n",
    "\n",
    "Градиентный спуск (SGD) — это не самый оптимальный алгоритм обучения нейронной сети. Если величина шага слишком маленькая, сеть будет обучаться долго, а если большая — может пропустить минимум. Чтобы подбор шага был автоматическим, применяют алгоритм **Adam** _(от англ. adaptive moment estimation, «адаптивность на основе оценки моментов»)_. Он подбирает различные параметры для разных нейронов, что также ускоряет обучение модели.\n",
    "\n",
    "Чтобы понять, как этот алгоритм работает, рассмотрим визуализацию Эмильена Дюпона из Оксфордского университета. В ней четыре алгоритма: слева SGD, справа Adam, а между ними — два похожих на Adam алгоритма (их разбирать не будем). Быстрее всех минимум находит Adam.\n",
    "\n",
    "Запишем алгоритм Adam в Keras:\n",
    "\n",
    "`model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['acc'])`\n",
    "\n",
    "Чтобы настроить гиперпараметры, подключим класс алгоритма:\n",
    "\n",
    "`from tensorflow.keras.optimizers import Adam optimizer = Adam()`\n",
    "\n",
    "`model.compile(optimizer=optimizer, loss='sparse_categorical_crossentropy', metrics=['acc'])`\n",
    "\n",
    "Основной настраиваемый гиперпараметр в алгоритме Adam — скорость обучения (learning rate). Это шаг градиентного спуска, с которого алгоритм стартует. Записывается так:\n",
    "\n",
    "`optimizer = Adam(lr=0.01)`\n",
    "\n",
    "По умолчанию он равен 0.001. Уменьшение шага иногда может замедлить обучение, но улучшить итоговое качество модели.\n",
    "\n",
    "Сначала ваш код должен пройти предварительную проверку, а затем его поставят в очередь на обучение. В это время вы можете вернуться в основной курс и продолжить изучать уроки о компьютерном зрении. Когда пройдёт 2–3 часа, загляните в этот урок и \n",
    "проверьте, не завершилось ли обучение модели. Перейти к следующей задаче вы сможете только после того, как решите эту."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "50fa62d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Подключение библиотеки\n",
    "from tensorflow.keras.datasets import fashion_mnist\n",
    "from tensorflow.keras.layers import Dense, AvgPool2D, Conv2D, Flatten\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "41b6b893",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Загрузка обучающей выборки\n",
    "def load_train(path):\n",
    "    # Получение целевого признака и признака\n",
    "    features_train = np.load(path + 'train_features.npy')\n",
    "    target_train = np.load(path + 'train_target.npy')\n",
    "    \n",
    "    # Приводим значения пикселей к диапазону [0, 1]\n",
    "    features_train = features_train.reshape(-1, 28, 28, 1) / 255.\n",
    "    \n",
    "    return features_train, target_train "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f72c895e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Создание модели\n",
    "def create_model(input_shape):\n",
    "    # Инициализируем модель машинного обучения\n",
    "    model = Sequential()\n",
    "    \n",
    "    model.add(Conv2D(filters=6, kernel_size=(5, 5), padding='same', input_shape=input_shape, activation='relu'))\n",
    "    \n",
    "    model.add(AvgPool2D(pool_size=(2, 2), strides=None, padding='valid'))\n",
    "    \n",
    "    model.add(Conv2D(filters=16, kernel_size=(5, 5), padding='valid', activation='relu'))\n",
    "    \n",
    "    model.add(AvgPool2D(pool_size=(2, 2), strides=None, padding='valid'))\n",
    "    \n",
    "    model.add(Flatten())\n",
    "\n",
    "    model.add(Dense(units=120, input_shape=input_shape, activation='relu'))\n",
    "    \n",
    "    model.add(Dense(units=84, activation='relu'))\n",
    "    \n",
    "    model.add(Dense(units=10, activation='softmax'))\n",
    "    \n",
    "    # Для настройки гиперпараметров: Основной настраиваемый гиперпараметр в алгоритме Adam — скорость обучения (learning rate). \n",
    "    # Это шаг градиентного спуска, с которого алгоритм стартует.\n",
    "    # По умолчанию он равен 0.001. Уменьшение шага иногда может замедлить обучение, но улучшить итоговое качество модели.\n",
    "    optimizer_adam = Adam(lr=0.01)\n",
    "    \n",
    "    # Также устанавливаем параметры, отвечающие за обучение\n",
    "    model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['acc'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d8404331",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Запуск модели\n",
    "def train_model(model, train_data, test_data, batch_size=32, epochs=10, steps_per_epoch=None, validation_steps=None):\n",
    "    # Деление обучающие выборки на признак и целевой признак\n",
    "    features_train, target_train = train_data\n",
    "    # Деление тестовой выборки на признак и целевой признак\n",
    "    features_test, target_test = test_data\n",
    "    # Обучаем модель\n",
    "    model.fit(features_train, target_train, \n",
    "              validation_data=(features_test, target_test),\n",
    "              batch_size=batch_size, epochs=epochs,\n",
    "              steps_per_epoch=steps_per_epoch,\n",
    "              validation_steps=validation_steps,\n",
    "              verbose=2, shuffle=True)\n",
    "\n",
    "    return model "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99ade97c",
   "metadata": {},
   "source": [
    "# Вывод на консольное окно"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13cc72cb",
   "metadata": {},
   "source": [
    "```\n",
    "2023-05-11 21:41:15.532867: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libnvinfer.so.6\n",
    "2023-05-11 21:41:15.534503: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libnvinfer_plugin.so.6\n",
    "2023-05-11 21:41:16.346028: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1\n",
    "2023-05-11 21:41:16.355707: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1555] Found device 0 with properties: \n",
    "pciBusID: 0000:8b:00.0 name: Tesla V100-SXM2-32GB computeCapability: 7.0\n",
    "coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 31.75GiB deviceMemoryBandwidth: 836.37GiB/s\n",
    "2023-05-11 21:41:16.355767: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
    "2023-05-11 21:41:16.355798: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n",
    "2023-05-11 21:41:16.357591: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\n",
    "2023-05-11 21:41:16.357960: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\n",
    "2023-05-11 21:41:16.359930: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\n",
    "2023-05-11 21:41:16.361060: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\n",
    "2023-05-11 21:41:16.361113: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
    "2023-05-11 21:41:16.365331: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1697] Adding visible gpu devices: 0\n",
    "Using TensorFlow backend.\n",
    "2023-05-11 21:41:17.001927: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA\n",
    "2023-05-11 21:41:17.008937: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2099995000 Hz\n",
    "2023-05-11 21:41:17.009468: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x44c4840 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
    "2023-05-11 21:41:17.009497: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
    "2023-05-11 21:41:17.151900: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x43e5000 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
    "2023-05-11 21:41:17.151938: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Tesla V100-SXM2-32GB, Compute Capability 7.0\n",
    "2023-05-11 21:41:17.154289: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1555] Found device 0 with properties: \n",
    "pciBusID: 0000:8b:00.0 name: Tesla V100-SXM2-32GB computeCapability: 7.0\n",
    "coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 31.75GiB deviceMemoryBandwidth: 836.37GiB/s\n",
    "2023-05-11 21:41:17.154349: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
    "2023-05-11 21:41:17.154359: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n",
    "2023-05-11 21:41:17.154384: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\n",
    "2023-05-11 21:41:17.154395: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\n",
    "2023-05-11 21:41:17.154405: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\n",
    "2023-05-11 21:41:17.154416: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\n",
    "2023-05-11 21:41:17.154423: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
    "2023-05-11 21:41:17.158730: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1697] Adding visible gpu devices: 0\n",
    "2023-05-11 21:41:17.158787: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
    "2023-05-11 21:41:17.469485: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1096] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
    "2023-05-11 21:41:17.469533: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1102]      0 \n",
    "2023-05-11 21:41:17.469541: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] 0:   N \n",
    "2023-05-11 21:41:17.473857: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
    "2023-05-11 21:41:17.473909: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1241] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10240 MB memory) -> physical GPU (device: 0, name: Tesla V100-SXM2-32GB, pci bus id: 0000:8b:00.0, compute capability: 7.0)\n",
    "<class 'tensorflow.python.keras.engine.sequential.Sequential'>\n",
    "Train on 60000 samples, validate on 10000 samples\n",
    "Epoch 1/10\n",
    "2023-05-11 21:41:18.833371: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n",
    "2023-05-11 21:41:19.109579: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
    "60000/60000 - 7s - loss: 0.5671 - acc: 0.7901 - val_loss: 0.4547 - val_acc: 0.8334\n",
    "Epoch 2/10\n",
    "60000/60000 - 5s - loss: 0.3861 - acc: 0.8580 - val_loss: 0.3942 - val_acc: 0.8622\n",
    "Epoch 3/10\n",
    "60000/60000 - 5s - loss: 0.3287 - acc: 0.8802 - val_loss: 0.3354 - val_acc: 0.8791\n",
    "Epoch 4/10\n",
    "60000/60000 - 5s - loss: 0.2960 - acc: 0.8918 - val_loss: 0.3107 - val_acc: 0.8881\n",
    "Epoch 5/10\n",
    "60000/60000 - 5s - loss: 0.2714 - acc: 0.8992 - val_loss: 0.3002 - val_acc: 0.8946\n",
    "Epoch 6/10\n",
    "60000/60000 - 5s - loss: 0.2526 - acc: 0.9050 - val_loss: 0.2986 - val_acc: 0.8921\n",
    "Epoch 7/10\n",
    "60000/60000 - 5s - loss: 0.2373 - acc: 0.9114 - val_loss: 0.2790 - val_acc: 0.8992\n",
    "Epoch 8/10\n",
    "60000/60000 - 5s - loss: 0.2217 - acc: 0.9164 - val_loss: 0.2881 - val_acc: 0.8989\n",
    "Epoch 9/10\n",
    "60000/60000 - 5s - loss: 0.2100 - acc: 0.9218 - val_loss: 0.2789 - val_acc: 0.9027\n",
    "Epoch 10/10\n",
    "60000/60000 - 5s - loss: 0.2003 - acc: 0.9244 - val_loss: 0.2748 - val_acc: 0.9034\n",
    "10000/10000 - 1s - loss: 0.2748 - acc: 0.9034\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
